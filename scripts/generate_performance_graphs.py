#!/usr/bin/env python3
print("HEAD")
"""
Performance visualization script for HTTP/3 vs HTTP/2 comparison
Shows the performance reversal phenomenon under different network conditions
"""

import os
import sys
import csv
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib import rcParams
import seaborn as sns
from datetime import datetime
import glob
import re
import matplotlib
import shutil
import argparse
matplotlib.rcParams['font.family'] = ['DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
from matplotlib.font_manager import FontProperties, findSystemFonts
import matplotlib.font_manager as fm

# --- Êó•Êú¨Ë™û„Éï„Ç©„É≥„ÉàËá™ÂãïÊ§úÂá∫ ---
def detect_japanese_font():
    candidates = [
        'Noto Sans CJK JP', 'Noto Serif CJK JP', 'IPAPGothic', 'IPAÊòéÊúù', 'IPAMincho',
        'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'VL PGothic', 'DejaVu Sans'
    ]
    available = [f.name for f in fm.fontManager.ttflist]
    for font in candidates:
        if font in available:
            return font
    return 'DejaVu Sans'

# --- matplotlibË®≠ÂÆö ---
detected_font = detect_japanese_font()
jp_font = FontProperties(family=detected_font)
matplotlib.rcParams['font.family'] = [detected_font]
matplotlib.rcParams['axes.unicode_minus'] = False

# „Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éë„É©„É°„Éº„ÇøÔºàrun_bench.sh„Å®Âêà„Çè„Åõ„ÇãÔºâ
BENCHMARK_PARAMS = [
    ('Á∑è„É™„ÇØ„Ç®„Çπ„ÉàÊï∞', '10000'),
    ('ÂêåÊôÇÊé•Á∂öÊï∞', '100'),
    ('‰∏¶Âàó„Çπ„É¨„ÉÉ„ÉâÊï∞', '20'),
    ('ÊúÄÂ§ßÂêåÊôÇ„Çπ„Éà„É™„Éº„É†Êï∞', '100'),
    ('„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó„É™„ÇØ„Ç®„Çπ„ÉàÊï∞', '1000'),
    ('Ê∏¨ÂÆö„É™„ÇØ„Ç®„Çπ„ÉàÊï∞', '9000'),
    ('„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„ÉóÊôÇÈñì(Áßí)', '2'),
]

def load_extreme_conditions_data(csv_file):
    """Load extreme conditions test data"""
    data = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # Convert string values to appropriate types
                processed_row = {}
                for key, value in row.items():
                    if key in ['Delay (ms)', 'Loss (%)', 'Bandwidth (Mbps)']:
                        processed_row[key] = int(float(value)) if value else 0
                    elif key in ['HTTP/2 Throughput (req/s)', 'HTTP/3 Throughput (req/s)', 
                               'HTTP/2 Latency (ms)', 'HTTP/3 Latency (ms)',
                               'HTTP/2 Connection Time (ms)', 'HTTP/3 Connection Time (ms)',
                               'Throughput Advantage (%)', 'Latency Advantage (%)', 'Connection Advantage (%)']:
                        processed_row[key] = float(value) if value else 0
                    else:
                        processed_row[key] = value
                data.append(processed_row)
    except Exception as e:
        print(f"Error loading data: {e}")
        return []
    
    return data

def create_performance_comparison_graphs(data, output_dir):
    """Create comprehensive performance comparison graphs"""
    
    # Sort data by delay for better visualization
    data.sort(key=lambda x: x['Delay (ms)'])
    
    # Extract data for plotting (È´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ‰∏ÄÂ∫¶„Å´ÊäΩÂá∫)
    delays = []
    bandwidths = []
    losses = []
    h2_throughput = []
    h3_throughput = []
    h2_latency = []
    h3_latency = []
    h2_connection = []
    h3_connection = []
    throughput_advantage = []
    latency_advantage = []
    connection_advantage = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        losses.append(row['Loss (%)'])
        h2_throughput.append(row['HTTP/2 Throughput (req/s)'])
        h3_throughput.append(row['HTTP/3 Throughput (req/s)'])
        h2_latency.append(row['HTTP/2 Latency (ms)'])
        h3_latency.append(row['HTTP/3 Latency (ms)'])
        h2_connection.append(row['HTTP/2 Connection Time (ms)'])
        h3_connection.append(row['HTTP/3 Connection Time (ms)'])
        throughput_advantage.append(row['Throughput Advantage (%)'])
        latency_advantage.append(row['Latency Advantage (%)'])
        connection_advantage.append(row['Connection Advantage (%)'])
    
    # Create figure with subplots
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('HTTP/3 vs HTTP/2 Performance Comparison', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Throughput comparison
    ax1 = axes[0, 0]
    x = np.arange(len(delays))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, h2_throughput, width, label='HTTP/2', color='skyblue', alpha=0.8)
    bars2 = ax1.bar(x + width/2, h3_throughput, width, label='HTTP/3', color='orange', alpha=0.8)
    
    ax1.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax1.set_ylabel('Throughput (req/s)', fontproperties=jp_font)
    ax1.set_title('Throughput Comparison', fontproperties=jp_font, fontweight='bold')
    ax1.set_xticks(x)
    ax1.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + max(h2_throughput + h3_throughput) * 0.01,
                f'{height:.0f}', ha='center', va='bottom', fontsize=8)
    
    for bar in bars2:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + max(h2_throughput + h3_throughput) * 0.01,
                f'{height:.0f}', ha='center', va='bottom', fontsize=8)
    
    # 2. Latency comparison
    ax2 = axes[0, 1]
    bars3 = ax2.bar(x - width/2, h2_latency, width, label='HTTP/2', color='skyblue', alpha=0.8)
    bars4 = ax2.bar(x + width/2, h3_latency, width, label='HTTP/3', color='orange', alpha=0.8)
    
    ax2.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax2.set_ylabel('Latency (ms)', fontproperties=jp_font)
    ax2.set_title('Latency Comparison', fontproperties=jp_font, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars3:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + max(h2_latency + h3_latency) * 0.01,
                f'{height:.1f}', ha='center', va='bottom', fontsize=8)
    
    for bar in bars4:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + max(h2_latency + h3_latency) * 0.01,
                f'{height:.1f}', ha='center', va='bottom', fontsize=8)
    
    # 3. Connection time comparison
    ax3 = axes[0, 2]
    bars5 = ax3.bar(x - width/2, h2_connection, width, label='HTTP/2', color='skyblue', alpha=0.8)
    bars6 = ax3.bar(x + width/2, h3_connection, width, label='HTTP/3', color='orange', alpha=0.8)
    
    ax3.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax3.set_ylabel('Connection Time (ms)', fontproperties=jp_font)
    ax3.set_title('Connection Time Comparison', fontproperties=jp_font, fontweight='bold')
    ax3.set_xticks(x)
    ax3.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars5:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + max(h2_connection + h3_connection) * 0.01,
                f'{height:.1f}', ha='center', va='bottom', fontsize=8)
    
    for bar in bars6:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + max(h2_connection + h3_connection) * 0.01,
                f'{height:.1f}', ha='center', va='bottom', fontsize=8)
    
    # 4. Throughput advantage (percentage)
    ax4 = axes[1, 0]
    colors = ['red' if adv < 0 else 'green' for adv in throughput_advantage]
    bars7 = ax4.bar(x, throughput_advantage, color=colors, alpha=0.7)
    
    ax4.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax4.set_ylabel('HTTP/3 Advantage (%)', fontproperties=jp_font)
    ax4.set_title('Throughput Advantage (Positive=HTTP/3 Superior)', fontproperties=jp_font, fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax4.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars7:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)
    
    # 5. Latency advantage (percentage)
    ax5 = axes[1, 1]
    colors = ['red' if adv < 0 else 'green' for adv in latency_advantage]
    bars8 = ax5.bar(x, latency_advantage, color=colors, alpha=0.7)
    
    ax5.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax5.set_ylabel('HTTP/3 Advantage (%)', fontproperties=jp_font)
    ax5.set_title('Latency Advantage (Positive=HTTP/3 Superior)', fontproperties=jp_font, fontweight='bold')
    ax5.set_xticks(x)
    ax5.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax5.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax5.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars8:
        height = bar.get_height()
        ax5.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)
    
    # 6. Connection time advantage (percentage)
    ax6 = axes[1, 2]
    colors = ['red' if adv < 0 else 'green' for adv in connection_advantage]
    bars9 = ax6.bar(x, connection_advantage, color=colors, alpha=0.7)
    
    ax6.set_xlabel('Network Conditions (Delay ms, Loss %, Bandwidth Mbps)', fontproperties=jp_font)
    ax6.set_ylabel('HTTP/3 Advantage (%)', fontproperties=jp_font)
    ax6.set_title('Connection Time Advantage (Positive=HTTP/3 Superior)', fontproperties=jp_font, fontweight='bold')
    ax6.set_xticks(x)
    ax6.set_xticklabels([f"{d}ms\n{l}%\n{b}Mbps" for d, l, b in zip(delays, losses, bandwidths)], rotation=45, ha='right')
    ax6.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax6.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars9:
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    
    # ‰øùÂ≠òÂâç„Å´Canvas„ÇíÊòéÁ§∫ÁöÑ„Å´ÊèèÁîª„Åó„Å¶„Åã„Çâ‰∏°Êñπ‰øùÂ≠ò
    fig.canvas.draw()
    output_file1 = os.path.join(output_dir, 'performance_comparison_overview.png')
    output_file2 = os.path.join(output_dir, 'test_conditions_and_network_environment.png')
    plt.savefig(output_file1, dpi=150, bbox_inches='tight')
    plt.close()
    shutil.copyfile(output_file1, output_file2)
    print(f"Performance Comparison Overview Graph Generation Completed: {output_file1} „Åä„Çà„Å≥ {output_file2}")

def create_detailed_analysis_graphs(data, output_dir):
    """Create detailed analysis graphs showing the reversal phenomenon"""
    
    # Sort data by delay
    data.sort(key=lambda x: x['Delay (ms)'])
    
    # È´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ‰∏ÄÂ∫¶„Å´„Éá„Éº„ÇøÊäΩÂá∫
    delays = []
    bandwidths = []
    throughput_advantage = []
    latency_advantage = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        throughput_advantage.append(row['Throughput Advantage (%)'])
        latency_advantage.append(row['Latency Advantage (%)'])
    
    # Create detailed analysis figure
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('HTTP/3 vs HTTP/2 ÊÄßËÉΩÈÄÜËª¢ÁèæË±° Ë©≥Á¥∞ÂàÜÊûê', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Throughput advantage trend
    ax1 = axes[0, 0]
    ax1.plot(delays, throughput_advantage, 'o-', linewidth=2, markersize=8, 
             color='#2E8B57', label='„Çπ„É´„Éº„Éó„ÉÉ„ÉàÂÑ™‰ΩçÊÄß', alpha=0.7)
    ax1.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='ÂùáË°°„É©„Ç§„É≥')
    ax1.set_xlabel('ÈÅÖÂª∂ (ms)', fontproperties=jp_font)
    ax1.set_ylabel('HTTP/3ÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    ax1.set_title('ÈÅÖÂª∂„Å®„Çπ„É´„Éº„Éó„ÉÉ„ÉàÂÑ™‰ΩçÊÄß„ÅÆÈñ¢‰øÇ', fontproperties=jp_font)
    ax1.grid(True, alpha=0.3)
    ax1.legend(prop=jp_font)
    
    # Add annotations for key points
    for i, (delay, adv) in enumerate(zip(delays, throughput_advantage)):
        if adv > 0:
            ax1.annotate(f'+{adv:.1f}%', (delay, adv), 
                        xytext=(10, 10), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        else:
            ax1.annotate(f'{adv:.1f}%', (delay, adv), 
                        xytext=(10, -15), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    # 2. Bandwidth vs throughput advantage
    ax2 = axes[0, 1]
    scatter = ax2.scatter(bandwidths, throughput_advantage, c=delays, 
                         s=100, cmap='viridis', alpha=0.7)
    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7)
    ax2.set_xlabel('Â∏ØÂüüÂπÖ (Mbps)', fontproperties=jp_font)
    ax2.set_ylabel('HTTP/3ÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    ax2.set_title('Â∏ØÂüüÂπÖ„Å®„Çπ„É´„Éº„Éó„ÉÉ„ÉàÂÑ™‰ΩçÊÄß„ÅÆÈñ¢‰øÇ', fontproperties=jp_font)
    ax2.grid(True, alpha=0.3)
    
    # Add colorbar
    cbar = plt.colorbar(scatter, ax=ax2)
    cbar.set_label('ÈÅÖÂª∂ (ms)', fontproperties=jp_font)
    
    # 3. Performance reversal threshold analysis
    ax3 = axes[1, 0]
    
    # Create threshold visualization
    threshold_delay = 300  # Approximate threshold where HTTP/3 starts to show advantage
    threshold_bandwidth = 10  # Approximate bandwidth threshold
    
    # Color code based on conditions
    colors = []
    for delay, bw, adv in zip(delays, bandwidths, throughput_advantage):
        if delay >= threshold_delay and bw <= threshold_bandwidth:
            colors.append('green')  # HTTP/3 advantage zone
        elif adv > 0:
            colors.append('lightgreen')  # HTTP/3 advantage
        else:
            colors.append('lightcoral')  # HTTP/2 advantage
    
    bars = ax3.bar(range(len(delays)), throughput_advantage, color=colors, alpha=0.8)
    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax3.set_xlabel('„ÉÜ„Çπ„Éà„Ç±„Éº„Çπ', fontproperties=jp_font)
    ax3.set_ylabel('HTTP/3ÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    ax3.set_title('ÊÄßËÉΩÈÄÜËª¢ÈñæÂÄ§ÂàÜÊûê', fontproperties=jp_font)
    ax3.set_xticks(range(len(delays)))
    ax3.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # Add threshold line
    ax3.axvline(x=2.5, color='red', linestyle='--', alpha=0.7, label='Êé®ÂÆöÈñæÂÄ§')
    ax3.legend(prop=jp_font)
    
    # 4. Comprehensive performance matrix
    ax4 = axes[1, 1]
    
    # Create a heatmap-like visualization
    x_pos = np.arange(len(delays))
    y_pos = np.arange(3)
    
    # Create performance matrix
    performance_matrix = np.array([
        throughput_advantage,
        latency_advantage,
        [row['Connection Advantage (%)'] for row in data]
    ])
    
    im = ax4.imshow(performance_matrix, cmap='RdYlGn', aspect='auto', 
                    vmin=-100, vmax=100, alpha=0.8)
    
    # Add text annotations
    for i in range(len(delays)):
        for j in range(3):
            value = performance_matrix[j, i]
            color = 'white' if abs(value) > 50 else 'black'
            ax4.text(i, j, f'{value:.1f}%', ha='center', va='center', 
                    color=color, fontweight='bold', fontproperties=jp_font)
    
    ax4.set_xticks(range(len(delays)))
    ax4.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], rotation=45)
    ax4.set_yticks(range(3))
    ax4.set_yticklabels(['„Çπ„É´„Éº„Éó„ÉÉ„Éà', '„É¨„Ç§„ÉÜ„É≥„Ç∑', 'Êé•Á∂öÊôÇÈñì'], fontweight='bold', fontproperties=jp_font)
    ax4.set_title('ÊÄßËÉΩÊØîËºÉ„Éû„Éà„É™„ÇØ„Çπ\n(Á∑ë=HTTP/3ÂÑ™‰Ωç„ÄÅËµ§=HTTP/2ÂÑ™‰Ωç)', fontproperties=jp_font)
    
    # Add colorbar
    cbar2 = plt.colorbar(im, ax=ax4)
    cbar2.set_label('HTTP/3ÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'detailed_performance_analysis.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # Create summary statistics
    create_summary_statistics(data, output_dir)

def create_summary_statistics(data, output_dir):
    """Create summary statistics and key findings"""
    
    # Calculate summary statistics (È´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ‰∏ÄÂ∫¶„Å´ÊäΩÂá∫)
    throughput_advantages = []
    latency_advantages = []
    connection_advantages = []
    
    for row in data:
        throughput_advantages.append(row['Throughput Advantage (%)'])
        latency_advantages.append(row['Latency Advantage (%)'])
        connection_advantages.append(row['Connection Advantage (%)'])
    
    # Find conditions where HTTP/3 is advantageous
    h3_advantage_conditions = [i for i, adv in enumerate(throughput_advantages) if adv > 0]
    h2_advantage_conditions = [i for i, adv in enumerate(throughput_advantages) if adv < 0]
    
    # Create summary figure
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    fig.suptitle('ÊÄßËÉΩÈÄÜËª¢ÁèæË±°„ÅÆÁµ±Ë®àÂàÜÊûê', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Advantage distribution
    ax1 = axes[0]
    categories = ['HTTP/3ÂÑ™‰Ωç', 'HTTP/2ÂÑ™‰Ωç']
    counts = [len(h3_advantage_conditions), len(h2_advantage_conditions)]
    colors = ['#2E8B57', '#CD5C5C']
    
    bars = ax1.bar(categories, counts, color=colors, alpha=0.8)
    ax1.set_ylabel('„ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÊï∞', fontproperties=jp_font)
    ax1.set_title('ÂÑ™‰ΩçÊÄßÂàÜÂ∏É', fontproperties=jp_font)
    
    # Add value labels
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{count}‰ª∂', ha='center', va='bottom', fontweight='bold', fontproperties=jp_font)
    
    # 2. Performance metrics summary
    ax2 = axes[1]
    
    metrics = ['„Çπ„É´„Éº„Éó„ÉÉ„Éà', '„É¨„Ç§„ÉÜ„É≥„Ç∑', 'Êé•Á∂öÊôÇÈñì']
    avg_advantages = [
        np.mean(throughput_advantages),
        np.mean(latency_advantages),
        np.mean(connection_advantages)
    ]
    
    colors = ['green' if adv > 0 else 'red' for adv in avg_advantages]
    bars = ax2.bar(metrics, avg_advantages, color=colors, alpha=0.8)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax2.set_ylabel('Âπ≥ÂùáÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    ax2.set_title('Âπ≥ÂùáÊÄßËÉΩÊØîËºÉ', fontproperties=jp_font)
    ax2.grid(True, alpha=0.3)
    
    # Add value labels
    for bar, adv in zip(bars, avg_advantages):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + (1 if adv >= 0 else -1),
                f'{adv:.1f}%', ha='center', va='bottom' if adv >= 0 else 'top', fontweight='bold', fontproperties=jp_font)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_summary_statistics.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # Generate summary report
    generate_summary_report(data, output_dir)

def generate_summary_report(data, output_dir):
    """Generate a summary report with key findings"""
    
    report_file = os.path.join(output_dir, 'performance_reversal_summary.txt')
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("HTTP/3 vs HTTP/2 Performance Reversal Phenomenon Detailed Analysis Report\n")
        f.write("=" * 80 + "\n")
        f.write(f"Generated Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # Calculate key statistics (È´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ‰∏ÄÂ∫¶„Å´ÊäΩÂá∫)
        throughput_advantages = []
        latency_advantages = []
        connection_advantages = []
        
        for row in data:
            throughput_advantages.append(row['Throughput Advantage (%)'])
            latency_advantages.append(row['Latency Advantage (%)'])
            connection_advantages.append(row['Connection Advantage (%)'])
        
        h3_advantage_count = sum(1 for adv in throughput_advantages if adv > 0)
        h2_advantage_count = sum(1 for adv in throughput_advantages if adv < 0)
        
        f.write("üìä Main Findings\n")
        f.write("-" * 40 + "\n")
        f.write(f"‚Ä¢ HTTP/3 Advantage Cases: {h3_advantage_count}/{len(data)} Cases\n")
        f.write(f"‚Ä¢ HTTP/2 Advantage Cases: {h2_advantage_count}/{len(data)} Cases\n")
        f.write(f"‚Ä¢ Average Throughput Advantage: {np.mean(throughput_advantages):.1f}%\n")
        f.write(f"‚Ä¢ Average Latency Advantage: {np.mean(latency_advantages):.1f}%\n")
        f.write(f"‚Ä¢ Average Connection Time Advantage: {np.mean(connection_advantages):.1f}%\n\n")
        
        f.write("üéØ Performance Reversal Threshold\n")
        f.write("-" * 40 + "\n")
        
        # Find threshold conditions
        threshold_conditions = []
        for row in data:
            if row['Throughput Advantage (%)'] > 0:
                threshold_conditions.append({
                    'delay': row['Delay (ms)'],
                    'bandwidth': row['Bandwidth (Mbps)'],
                    'loss': row['Loss (%)'],
                    'advantage': row['Throughput Advantage (%)']
                })
        
        if threshold_conditions:
            f.write("HTTP/3 Advantage Conditions:\n")
            for condition in threshold_conditions:
                f.write(f"  ‚Ä¢ {condition['delay']}ms Delay, {condition['bandwidth']}Mbps Bandwidth, {condition['loss']}% Loss ‚Üí +{condition['advantage']:.1f}%\n")
        
        f.write("\nüöÄ Most Prominent Results\n")
        f.write("-" * 40 + "\n")
        
        # Find maximum advantage
        max_advantage = max(throughput_advantages)
        max_condition = data[throughput_advantages.index(max_advantage)]
        f.write(f"‚Ä¢ Maximum Throughput Advantage: +{max_advantage:.1f}%\n")
        f.write(f"  Conditions: {max_condition['Delay (ms)']}ms Delay, {max_condition['Bandwidth (Mbps)']}Mbps Bandwidth, {max_condition['Loss (%)']}% Loss\n")
        
        f.write("\nüìà Research Hypothesis Verification Results\n")
        f.write("-" * 40 + "\n")
        f.write("‚úÖ Repeated Claims:\n")
        f.write("  ‚Ä¢ HTTP/3 Advantage in Extremely High Delay Environment\n")
        f.write("  ‚Ä¢ HTTP/3 Advantage in Extremely Low Bandwidth Environment\n")
        f.write("  ‚Ä¢ Performance Reversal Phenomenon in Specific Conditions\n\n")
        
        f.write("‚ùå Unrepeated Parts:\n")
        f.write("  ‚Ä¢ HTTP/2 Consistently Advantageous in Latency\n")
        f.write("  ‚Ä¢ HTTP/2 Advantageous in Connection Time\n\n")
        
        f.write("üîç Practical Guidelines\n")
        f.write("-" * 40 + "\n")
        f.write("‚Ä¢ Recommend HTTP/3 in environments with delay >= 400ms and bandwidth <= 10Mbps\n")
        f.write("‚Ä¢ Recommend HTTP/3 in satellite communication or extremely restrictive network environments\n")
        f.write("‚Ä¢ Recommend HTTP/2 in stable and advantageous general network environments\n")
        f.write("‚Ä¢ Select HTTP/2 if latency is important\n\n")
        
        f.write("üìÅ Generated Graph Files:\n")
        f.write("-" * 40 + "\n")
        f.write("‚Ä¢ performance_comparison_overview.png - Overall Performance Comparison\n")
        f.write("‚Ä¢ detailed_performance_analysis.png - Detailed Reversal Phenomenon Analysis\n")
        f.write("‚Ä¢ performance_summary_statistics.png - Statistical Summary\n")
    
    print(f"Summary Report Generation Completed: {report_file}")

def load_benchmark_csvs(log_dir):
    print(f"[DEBUG] load_benchmark_csvs received log_dir: {log_dir}")
    
    # „Åæ„Åöperformance_comparison.csv„ÇíÊé¢„Åô
    performance_csv = os.path.join(log_dir, 'performance_comparison.csv')
    if os.path.exists(performance_csv):
        print(f"Found performance_comparison.csv in {log_dir}")
        try:
            data = load_extreme_conditions_data(performance_csv)
            if data:
                return data
        except Exception as e:
            print(f"Error reading performance_comparison.csv: {e}")
    
    # ÂæìÊù•„ÅÆh2_*.csv, h3_*.csv„Éï„Ç°„Ç§„É´„ÇíÊé¢Á¥¢
    h2_csvs = sorted(glob.glob(os.path.join(log_dir, 'h2_*.csv')))
    h3_csvs = sorted(glob.glob(os.path.join(log_dir, 'h3_*.csv')))
    if not h2_csvs or not h3_csvs:
        print(f"Error: No benchmark CSV data found in {log_dir}")
        sys.exit(1)
    data = []
    def parse_case(filename):
        # ‰æã: h2_150ms_3pct.csv „Åæ„Åü„ÅØ h2_150ms_3pct_10mbps.csv
        base = os.path.basename(filename)
        parts = base.split('_')
        delay = int(parts[1].replace('ms',''))
        loss_part = parts[2]
        if 'mbps' in base:
            # Â∏ØÂüüÊåáÂÆö„ÅÇ„Çä
            loss = int(loss_part.replace('pct',''))
            bw = int(parts[3].replace('mbps.csv',''))
        else:
            # „Éï„Ç°„Ç§„É´Âêç„ÅÆÊú´Â∞æ„ÅÆ.csv„ÇíÈô§Âéª„Åó„Å¶„Åã„Çâpct„ÇíÈô§Âéª
            loss = int(loss_part.replace('pct.csv','').replace('pct',''))
            bw = 0
        return delay, loss, bw
    
    def extract_metrics_from_log(logfile):
        """È´òÈÄüÂåñ„Åï„Çå„Åü„É≠„Ç∞„Éï„Ç°„Ç§„É´„Åã„Çâ„ÅÆ„É°„Éà„É™„ÇØ„ÇπÊäΩÂá∫"""
        throughput = 0
        latency = 0
        connect = 0
        
        try:
            with open(logfile, 'r', encoding='utf-8') as f:
                # „Éï„Ç°„Ç§„É´„ÅÆÊúÄÂæå„ÅÆ100Ë°å„Å†„Åë„ÇíË™≠„ÅøËæº„Çì„ÅßÈ´òÈÄüÂåñ
                lines = f.readlines()[-100:]
                
            # ÈÄÜÈ†Ü„ÅßÊ§úÁ¥¢„Åó„Å¶ÊúÄÂàù„Å´Ë¶ã„Å§„Åã„Å£„Åü„ÇÇ„ÅÆ„Çí‰ΩøÁî®
            for line in reversed(lines):
                if 'time for request:' in line:
                    m = re.search(r'time for request:\s+([\d\.]+\w+)\s+([\d\.]+\w+)\s+([\d\.]+)ms', line)
                    if m:
                        latency = float(m.group(3))
                        break
                        
            for line in reversed(lines):
                if 'time for connect:' in line:
                    m = re.search(r'time for connect:\s+([\d\.]+\w+)\s+([\d\.]+\w+)\s+([\d\.]+)ms', line)
                    if m:
                        connect = float(m.group(3))
                        break
                        
            for line in reversed(lines):
                if 'finished in' in line and 'req/s' in line:
                    m = re.search(r'finished in [\d\.]+\w+, ([\d\.]+) req/s', line)
                    if m:
                        throughput = float(m.group(1))
                        break
                        
        except Exception as e:
            print(f"Warning: Error reading {logfile}: {e}")
            
        return throughput, latency, connect

    h2_map = {parse_case(f): f for f in h2_csvs}
    h3_map = {parse_case(f): f for f in h3_csvs}
    all_cases = sorted(set(h2_map.keys()) & set(h3_map.keys()))
    
    for case in all_cases:
        delay, loss, bw = case
        h2_csv = h2_map[case]
        h3_csv = h3_map[case]
        
        h2_log = h2_csv.replace('.csv', '.log')
        h3_log = h3_csv.replace('.csv', '.log')
        
        h2_throughput, h2_latency, h2_connect = extract_metrics_from_log(h2_log)
        h3_throughput, h3_latency, h3_connect = extract_metrics_from_log(h3_log)
        
        # ÂÑ™‰ΩçÊÄßË®àÁÆó
        throughput_adv = ((h3_throughput - h2_throughput) / h2_throughput * 100) if h2_throughput else 0
        latency_adv = ((h2_latency - h3_latency) / h2_latency * 100) if h2_latency else 0
        connect_adv = ((h2_connect - h3_connect) / h2_connect * 100) if h2_connect else 0
        
        data.append({
            'Delay (ms)': delay,
            'Loss (%)': loss,
            'Bandwidth (Mbps)': bw,
            'HTTP/2 Throughput (req/s)': h2_throughput,
            'HTTP/3 Throughput (req/s)': h3_throughput,
            'HTTP/2 Latency (ms)': h2_latency,
            'HTTP/3 Latency (ms)': h3_latency,
            'HTTP/2 Connection Time (ms)': h2_connect,
            'HTTP/3 Connection Time (ms)': h3_connect,
            'Throughput Advantage (%)': throughput_adv,
            'Latency Advantage (%)': latency_adv,
            'Connection Advantage (%)': connect_adv,
        })
    
    return data

def find_latest_benchmark_dir(base_dir="/logs"):
    """h2/h3_*.csv„ÅåÂ≠òÂú®„Åô„ÇãÊúÄÊñ∞„ÅÆ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíËøî„Åô"""
    if not os.path.exists(base_dir):
        return None
    benchmark_dirs = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path) and item.startswith("benchmark_"):
            # h2_*.csv„Åæ„Åü„ÅØh3_*.csv„Åå1„Å§„Åß„ÇÇÂ≠òÂú®„Åô„Çã„Åã
            h2_csvs = glob.glob(os.path.join(item_path, 'h2_*.csv'))
            h3_csvs = glob.glob(os.path.join(item_path, 'h3_*.csv'))
            if h2_csvs or h3_csvs:
                benchmark_dirs.append(item_path)
    if not benchmark_dirs:
        return None
    latest_dir = max(benchmark_dirs, key=os.path.getmtime)
    print(f"[DEBUG] find_latest_benchmark_dir returns: {latest_dir}")
    sys.stdout.flush()
    return latest_dir

def generate_graphs(log_dir):
    """ÊåáÂÆö„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆ„Éô„É≥„ÉÅ„Éû„Éº„ÇØCSV„Åã„Çâ„Ç∞„É©„Éï„ÇíÁîüÊàê„Åô„ÇãÁµ±ÂêàÈñ¢Êï∞"""
    data = load_benchmark_csvs(log_dir)
    create_performance_comparison_graphs(data, log_dir)
    create_detailed_analysis_graphs(data, log_dir)
    create_summary_statistics(data, log_dir)
    create_network_conditions_info(data, log_dir)
    generate_summary_report(data, log_dir)

def create_network_conditions_info(data, output_dir):
    """„ÉÜ„Çπ„ÉàÊù°‰ª∂„ÇÑ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈÄö‰ø°Áí∞Â¢É„ÅÆÊÉÖÂ†±„ÇíË°®Á§∫„Åô„Çã„Ç∞„É©„Éï„ÇíÁîüÊàê"""
    
    # „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊù°‰ª∂„ÅÆË©≥Á¥∞ÊÉÖÂ†±„ÇíÂèéÈõÜÔºàÈ´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ‰∏ÄÂ∫¶„Å´Âá¶ÁêÜÔºâ
    conditions_info = []
    delays = []
    losses = []
    bandwidths = []
    h2_throughputs = []
    h3_throughputs = []
    h2_latencies = []
    h3_latencies = []
    h2_connections = []
    h3_connections = []
    throughput_advantages = []
    latency_advantages = []
    connection_advantages = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        losses.append(row['Loss (%)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        h2_throughputs.append(row['HTTP/2 Throughput (req/s)'])
        h3_throughputs.append(row['HTTP/3 Throughput (req/s)'])
        h2_latencies.append(row['HTTP/2 Latency (ms)'])
        h3_latencies.append(row['HTTP/3 Latency (ms)'])
        h2_connections.append(row['HTTP/2 Connection Time (ms)'])
        h3_connections.append(row['HTTP/3 Connection Time (ms)'])
        throughput_advantages.append(row['Throughput Advantage (%)'])
        latency_advantages.append(row['Latency Advantage (%)'])
        connection_advantages.append(row['Connection Advantage (%)'])
        
        conditions_info.append({
            'delay': row['Delay (ms)'],
            'loss': row['Loss (%)'],
            'bandwidth': row['Bandwidth (Mbps)'],
            'h2_throughput': row['HTTP/2 Throughput (req/s)'],
            'h3_throughput': row['HTTP/3 Throughput (req/s)'],
            'h2_latency': row['HTTP/2 Latency (ms)'],
            'h3_latency': row['HTTP/3 Latency (ms)'],
            'h2_connection': row['HTTP/2 Connection Time (ms)'],
            'h3_connection': row['HTTP/3 Connection Time (ms)'],
            'throughput_advantage': row['Throughput Advantage (%)'],
            'latency_advantage': row['Latency Advantage (%)'],
            'connection_advantage': row['Connection Advantage (%)']
        })
    
    # Âõ≥„ÅÆ‰ΩúÊàê
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('„ÉÜ„Çπ„ÉàÊù°‰ª∂„Å®„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÁí∞Â¢ÉË®≠ÂÆö', fontsize=18, fontweight='bold', fontproperties=jp_font)
    
    # 1. „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊù°‰ª∂„ÅÆÂàÜÂ∏É
    ax1 = axes[0, 0]
    # delays, losses, bandwidths„ÅØÊó¢„Å´ÊäΩÂá∫Ê∏à„Åø
    
    # ÈÅÖÂª∂„ÅÆÂàÜÂ∏É
    ax1.scatter(delays, [1]*len(delays), c='red', s=100, alpha=0.7, label='ÈÅÖÂª∂ (ms)')
    ax1.scatter(losses, [0.8]*len(losses), c='blue', s=100, alpha=0.7, label='ÊêçÂ§±Áéá (%)')
    ax1.scatter(bandwidths, [0.6]*len(bandwidths), c='green', s=100, alpha=0.7, label='Â∏ØÂüüÂπÖ (Mbps)')
    
    ax1.set_xlabel('ÂÄ§', fontproperties=jp_font)
    ax1.set_ylabel('„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊù°‰ª∂', fontproperties=jp_font)
    ax1.set_title('ÈÅÖÂª∂„ÉªÊêçÂ§±„ÉªÂ∏ØÂüü„ÅÆÂàÜÂ∏É', fontproperties=jp_font)
    ax1.legend(['ÈÅÖÂª∂ (ms)', 'ÊêçÂ§±Áéá (%)', 'Â∏ØÂüüÂπÖ (Mbps)'], prop=jp_font)
    
    # ÂÄ§„ÅÆ„É©„Éô„É´„ÇíËøΩÂä†
    for i, (delay, loss, bw) in enumerate(zip(delays, losses, bandwidths)):
        ax1.annotate(f'{delay}ms', (delay, 1), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
        ax1.annotate(f'{loss}%', (loss, 0.8), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
        ax1.annotate(f'{bw}Mbps', (bw, 0.6), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
    
    # 2. ÊÄßËÉΩÊØîËºÉ„ÅÆË©≥Á¥∞Ë°®
    ax2 = axes[0, 1]
    ax2.axis('tight')
    ax2.axis('off')
    
    # „ÉÜ„Éº„Éñ„É´„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
    table_data = []
    headers = ['Êù°‰ª∂', 'HTTP/2', 'HTTP/3', 'ÂÑ™‰ΩçÊÄß']
    
    for i, condition in enumerate(conditions_info):
        cond_str = f"{condition['delay']}ms/{condition['loss']}%"
        
        # „Çπ„É´„Éº„Éó„ÉÉ„ÉàË°å
        h2_tp = f"{condition['h2_throughput']:.0f}"
        h3_tp = f"{condition['h3_throughput']:.0f}"
        tp_adv = f"{condition['throughput_advantage']:+.1f}%"
        table_data.append([cond_str + ' Throughput', h2_tp, h3_tp, tp_adv])
        
        # „É¨„Ç§„ÉÜ„É≥„Ç∑Ë°å
        h2_lat = f"{condition['h2_latency']:.3f}"
        h3_lat = f"{condition['h3_latency']:.3f}"
        lat_adv = f"{condition['latency_advantage']:+.1f}%"
        table_data.append([cond_str + ' Latency', h2_lat, h3_lat, lat_adv])
        
        # Êé•Á∂öÊôÇÈñìË°å
        h2_conn = f"{condition['h2_connection']:.3f}"
        h3_conn = f"{condition['h3_connection']:.3f}"
        conn_adv = f"{condition['connection_advantage']:+.1f}%"
        table_data.append([cond_str + ' Connection Time', h2_conn, h3_conn, conn_adv])
        
        if i < len(conditions_info) - 1:
            table_data.append(['', '', '', ''])  # Á©∫Ë°å
    
    table = ax2.table(cellText=table_data, colLabels=headers, cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1.1, 2)
    
    # „ÉÜ„Éº„Éñ„É´„ÅÆ„Çπ„Çø„Ç§„É´Ë®≠ÂÆö
    for i in range(len(headers)):
        table[(0, i)].set_facecolor('#4CAF50')
        table[(0, i)].set_text_props(weight='bold', color='white', fontproperties=jp_font)
    for i in range(1, len(table_data) + 1):
        if table_data[i-1][3] != '':
            advantage = table_data[i-1][3]
            if '+' in advantage:
                table[(i, 3)].set_facecolor('#90EE90')
            elif '-' in advantage:
                table[(i, 3)].set_facecolor('#FFB6C1')
    
    
    # 3. „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊù°‰ª∂„ÅÆÂΩ±ÈüøÂàÜÊûê
    ax3 = axes[1, 0]
    
    # ÈÅÖÂª∂„Å®„Çπ„É´„Éº„Éó„ÉÉ„ÉàÂÑ™‰ΩçÊÄß„ÅÆÈñ¢‰øÇÔºàÊó¢„Å´ÊäΩÂá∫Ê∏à„ÅøÔºâ
    
    colors = ['red' if adv < 0 else 'green' for adv in throughput_advantages]
    bars = ax3.bar(range(len(delays)), throughput_advantages, color=colors, alpha=0.7)
    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    
    ax3.set_xlabel('„ÉÜ„Çπ„Éà„Ç±„Éº„Çπ', fontproperties=jp_font)
    ax3.set_ylabel('HTTP/3ÂÑ™‰ΩçÊÄß (%)', fontproperties=jp_font)
    ax3.set_title('ÈÅÖÂª∂Êù°‰ª∂‰∏ã„Åß„ÅÆHTTP/3ÂÑ™‰ΩçÊÄß', fontproperties=jp_font)
    ax3.set_xticks(range(len(delays)))
    ax3.set_xticklabels([f"{c['delay']}ms\n{c['loss']}%" for c in conditions_info], rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # ÂÄ§„ÅÆ„É©„Éô„É´„ÇíËøΩÂä†
    for i, (bar, adv) in enumerate(zip(bars, throughput_advantages)):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -1),
                f'{adv:+.1f}%', ha='center', va='bottom' if height >= 0 else 'top', 
                fontsize=8, fontproperties=jp_font)
    
    # 4. „ÉÜ„Çπ„ÉàÁí∞Â¢É„ÅÆÊ¶ÇË¶Å
    ax4 = axes[1, 1]
    ax4.axis('tight')
    ax4.axis('off')
    
    # „ÉÜ„Çπ„ÉàÁí∞Â¢É„ÅÆÊÉÖÂ†±
    exec_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    # „Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éï„Ç°„Ç§„É´Âêç‰∏ÄË¶ß
    h2_files = sorted([f for f in os.listdir(output_dir) if f.startswith('h2_') and f.endswith('.csv')])
    h3_files = sorted([f for f in os.listdir(output_dir) if f.startswith('h3_') and f.endswith('.csv')])
    file_list = '\n'.join(h2_files + h3_files)

    env_info = [
        ['ÂÆüË°åÊó•ÊôÇ', exec_time],
        ['„ÉÜ„Çπ„ÉàÁí∞Â¢É', 'ÂÄ§'],
        ['„ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÊï∞', f"{len(conditions_info)}"],
        ['ÈÅÖÂª∂ÁØÑÂõ≤', f"{min(delays)}ms - {max(delays)}ms"],
        ['ÊêçÂ§±ÁØÑÂõ≤', f"{min(losses)}% - {max(losses)}%"],
        ['Â∏ØÂüüÁØÑÂõ≤', f"{min(bandwidths)}Mbps - {max(bandwidths)}Mbps"],
        ['HTTP/3ÂÑ™‰Ωç„Ç±„Éº„Çπ', f"{sum(1 for adv in throughput_advantages if adv > 0)}/{len(conditions_info)}"],
        ['HTTP/2ÂÑ™‰Ωç„Ç±„Éº„Çπ', f"{sum(1 for adv in throughput_advantages if adv < 0)}/{len(conditions_info)}"],
        ['Âπ≥Âùá„Çπ„É´„Éº„Éó„ÉÉ„ÉàÂÑ™‰ΩçÊÄß', f"{np.mean(throughput_advantages):.1f}%"],
        ['Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ÂÑ™‰ΩçÊÄß', f"{np.mean(latency_advantages):.1f}%"],
        ['Âπ≥ÂùáÊé•Á∂öÊôÇÈñìÂÑ™‰ΩçÊÄß', f"{np.mean(connection_advantages):.1f}%"],
        ['', ''],
        ['„Éô„É≥„ÉÅ„Éû„Éº„ÇØË®≠ÂÆö', ''],
    ]
    env_info += load_benchmark_params(output_dir)
    env_info.append(['', ''])
    env_info.append(['„Éô„É≥„ÉÅ„Éû„Éº„ÇØÂÆüË°å„Çπ„ÇØ„É™„Éó„Éà', 'run_bench.sh'])

    env_table = ax4.table(cellText=env_info, cellLoc='left', loc='center')
    env_table.auto_set_font_size(False)
    env_table.set_fontsize(9)
    env_table.scale(1.1, 1.5)
    # „Çª„É´ÂÜÖÊäò„ÇäËøî„Åó
    for i in range(len(env_info)):
        for j in range(2):
            cell = env_table[(i, j)]
            cell.set_text_props(fontproperties=jp_font, wrap=True)
    for i in range(len(env_info)):
        env_table[(i, 0)].set_facecolor('#2196F3')
        env_table[(i, 0)].set_text_props(weight='bold', color='white', fontproperties=jp_font)
        env_table[(i, 1)].set_facecolor('#E3F2FD')
    
    
    # Âõ≥„ÅÆË™øÊï¥
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    
    # ‰øùÂ≠òÂâç„Å´Canvas„ÇíÊòéÁ§∫ÁöÑ„Å´ÊèèÁîª„Åó„Å¶„Åã„Çâ‰∏°Êñπ‰øùÂ≠ò
    fig.canvas.draw()
    output_file1 = os.path.join(output_dir, 'network_conditions_info.png')
    output_file2 = os.path.join(output_dir, 'test_conditions_and_network_environment.png')
    plt.savefig(output_file1, dpi=150, bbox_inches='tight')
    plt.close()
    shutil.copyfile(output_file1, output_file2)
    print(f"Network Conditions Information Graph Generation Completed: {output_file1} „Åä„Çà„Å≥ {output_file2}")

def load_benchmark_params(log_dir):
    params_file = os.path.join(log_dir, 'benchmark_params.txt')
    params = []
    if os.path.exists(params_file):
        with open(params_file, 'r', encoding='utf-8') as f:
            for line in f:
                if '=' in line:
                    k, v = line.strip().split('=', 1)
                    label = {
                        'REQUESTS': 'Á∑è„É™„ÇØ„Ç®„Çπ„ÉàÊï∞',
                        'CONNECTIONS': 'ÂêåÊôÇÊé•Á∂öÊï∞',
                        'THREADS': '‰∏¶Âàó„Çπ„É¨„ÉÉ„ÉâÊï∞',
                        'MAX_CONCURRENT': 'ÊúÄÂ§ßÂêåÊôÇ„Çπ„Éà„É™„Éº„É†Êï∞',
                        'WARMUP_REQUESTS': '„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó„É™„ÇØ„Ç®„Çπ„ÉàÊï∞',
                        'MEASUREMENT_REQUESTS': 'Ê∏¨ÂÆö„É™„ÇØ„Ç®„Çπ„ÉàÊï∞',
                        'CONNECTION_WARMUP_TIME': '„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„ÉóÊôÇÈñì(Áßí)'
                    }.get(k, k)
                    params.append((label, v))
    return params

def integrate_multiple_cases(case_dirs, output_dir):
    """Ë§áÊï∞„ÅÆ„Ç±„Éº„Çπ„Éá„Ç£„É¨„ÇØ„Éà„É™„Åã„Çâ„Éá„Éº„Çø„ÇíÁµ±Âêà"""
    all_data = []
    
    for case_dir in case_dirs:
        if not os.path.exists(case_dir):
            print(f"Warning: Case directory not found: {case_dir}")
            continue
            
        # CSV„Éï„Ç°„Ç§„É´„ÇíÊé¢„Åô
        csv_files = glob.glob(os.path.join(case_dir, "*.csv"))
        if not csv_files:
            print(f"Warning: No CSV files found in {case_dir}")
            continue
            
        # ÊúÄÂàù„ÅÆCSV„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„Åø
        csv_file = csv_files[0]
        case_data = load_extreme_conditions_data(csv_file)
        
        # „Ç±„Éº„ÇπÂêç„ÇíËøΩÂä†
        case_name = os.path.basename(case_dir)
        for row in case_data:
            row['Case'] = case_name
            
        all_data.extend(case_data)
    
    if not all_data:
        print("Error: No data found in any case directory")
        return
    
    # Áµ±Âêà„Éá„Éº„Çø„ÇíCSV„Å´‰øùÂ≠ò
    csv_file = os.path.join(output_dir, 'integrated_results.csv')
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if all_data:
            writer = csv.DictWriter(f, fieldnames=all_data[0].keys())
            writer.writeheader()
            writer.writerows(all_data)
    
    print(f"Integrated data saved: {csv_file}")
    
    # „Éá„Éº„ÇøÂΩ¢Âºè„ÇíÂ§âÊèõ„Åó„Å¶Áµ±Âêà„Ç∞„É©„Éï„ÇíÁîüÊàê
    converted_data = convert_data_format(all_data)
    if converted_data:
        create_performance_comparison_graphs(converted_data, output_dir)
        create_detailed_analysis_graphs(converted_data, output_dir)
        create_summary_statistics(converted_data, output_dir)
        create_network_conditions_info(converted_data, output_dir)
        generate_summary_report(converted_data, output_dir)
        
        print(f"Integrated graphs created in: {output_dir}")
    else:
        print("Error: Failed to convert data format")

def convert_data_format(data):
    """„Éá„Éº„ÇøÂΩ¢Âºè„ÇíÂ§âÊèõ"""
    converted_data = []
    
    # Êù°‰ª∂„Åî„Å®„Å´„Éá„Éº„Çø„Çí„Ç∞„É´„Éº„ÉóÂåñ
    conditions = {}
    for row in data:
        delay = int(row.get('Delay (ms)', 0))
        loss = int(row.get('Loss (%)', 0))
        bandwidth = int(row.get('Bandwidth (Mbps)', 0))
        case = row.get('Case', 'unknown')
        
        key = (delay, loss, bandwidth, case)
        if key not in conditions:
            conditions[key] = {}
        
        protocol = row.get('Protocol', '').upper()
        if 'HTTP2' in protocol or 'HTTP/2' in protocol:
            conditions[key]['HTTP/2 Throughput (req/s)'] = float(row.get('Throughput (req/s)', 0))
            conditions[key]['HTTP/2 Latency (ms)'] = float(row.get('Latency (ms)', 0))
            conditions[key]['HTTP/2 Connection Time (ms)'] = float(row.get('Connection Time (ms)', 0))
        elif 'HTTP3' in protocol or 'HTTP/3' in protocol:
            conditions[key]['HTTP/3 Throughput (req/s)'] = float(row.get('Throughput (req/s)', 0))
            conditions[key]['HTTP/3 Latency (ms)'] = float(row.get('Latency (ms)', 0))
            conditions[key]['HTTP/3 Connection Time (ms)'] = float(row.get('Connection Time (ms)', 0))
    
    # Â§âÊèõ„Åï„Çå„Åü„Éá„Éº„Çø„Çí‰ΩúÊàê
    for (delay, loss, bandwidth, case), protocols in conditions.items():
        if 'HTTP/2 Throughput (req/s)' in protocols and 'HTTP/3 Throughput (req/s)' in protocols:
            h2_tp = protocols['HTTP/2 Throughput (req/s)']
            h3_tp = protocols['HTTP/3 Throughput (req/s)']
            h2_lat = protocols['HTTP/2 Latency (ms)']
            h3_lat = protocols['HTTP/3 Latency (ms)']
            h2_conn = protocols['HTTP/2 Connection Time (ms)']
            h3_conn = protocols['HTTP/3 Connection Time (ms)']
            
            # ÂÑ™‰ΩçÊÄß„ÇíË®àÁÆó
            throughput_adv = ((h3_tp - h2_tp) / h2_tp * 100) if h2_tp else 0
            latency_adv = ((h2_lat - h3_lat) / h2_lat * 100) if h2_lat else 0
            connect_adv = ((h2_conn - h3_conn) / h2_conn * 100) if h2_conn else 0
            
            converted_data.append({
                'Delay (ms)': delay,
                'Loss (%)': loss,
                'Bandwidth (Mbps)': bandwidth,
                'HTTP/2 Throughput (req/s)': h2_tp,
                'HTTP/3 Throughput (req/s)': h3_tp,
                'HTTP/2 Latency (ms)': h2_lat,
                'HTTP/3 Latency (ms)': h3_lat,
                'HTTP/2 Connection Time (ms)': h2_conn,
                'HTTP/3 Connection Time (ms)': h3_conn,
                'Throughput Advantage (%)': throughput_adv,
                'Latency Advantage (%)': latency_adv,
                'Connection Advantage (%)': connect_adv,
                'Case': case
            })
    
    return converted_data

if __name__ == "__main__":
    print("START")
    try:
        # ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Éù„Éº„ÉàÁ¢∫Ë™ç
        required_modules = ['numpy', 'matplotlib', 'seaborn', 'pandas']
        missing_modules = []
        
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)
        
        if missing_modules:
            print(f"Error: Missing required modules: {', '.join(missing_modules)}")
            print("Attempting to install missing modules...")
            
            import subprocess
            import sys
            
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user'] + missing_modules)
                print("Modules installed successfully. Retrying...")
                # „É¢„Ç∏„É•„Éº„É´„ÇíÂÜç„Ç§„É≥„Éù„Éº„Éà
                for module in missing_modules:
                    __import__(module)
            except subprocess.CalledProcessError:
                print("Failed to install modules automatically.")
                print("Please install manually: pip3 install --user numpy matplotlib seaborn pandas")
                sys.exit(1)
        
        # „Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„ÅÆËß£Êûê
        parser = argparse.ArgumentParser(description='Generate performance graphs from benchmark data')
        parser.add_argument('--log_dir', help='Log directory for single case')
        parser.add_argument('--integrate_cases', action='store_true', help='Integrate multiple cases')
        parser.add_argument('--case_dirs', nargs='+', help='Case directories for integration')
        
        args = parser.parse_args()
        
        if args.integrate_cases and args.case_dirs:
            # Áµ±Âêà„É¢„Éº„Éâ
            output_dir = args.log_dir if args.log_dir else "logs/integrated_results"
            os.makedirs(output_dir, exist_ok=True)
            integrate_multiple_cases(args.case_dirs, output_dir)
        else:
            # Âçò‰∏Ä„Ç±„Éº„Çπ„É¢„Éº„Éâ
            args_list = [a for a in sys.argv[1:] if not a.startswith('--')]
            if len(args_list) == 0:
                log_dir = find_latest_benchmark_dir(base_dir='/logs')
                if log_dir is None:
                    print("Error: Benchmark directory not found. Please create benchmark_* directory under '/logs'.")
                    sys.exit(1)
            elif len(args_list) == 1:
                log_dir = args_list[0]
            else:
                print("Usage: python3 generate_performance_graphs.py <log_dir>")
                sys.exit(1)
            
            # „É≠„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆÂ≠òÂú®Á¢∫Ë™ç
            if not os.path.exists(log_dir):
                print(f"Error: Log directory '{log_dir}' does not exist.")
                sys.exit(1)
            
            # ÂøÖË¶Å„Å™„Éï„Ç°„Ç§„É´„ÅÆÂ≠òÂú®Á¢∫Ë™ç
            csv_files = [f for f in os.listdir(log_dir) if f.endswith('.csv')]
            if not csv_files:
                print(f"Error: No CSV files found in '{log_dir}'")
                sys.exit(1)
            
            print(f"[DEBUG] load_benchmark_csvs received log_dir: {log_dir}")
            generate_graphs(log_dir)
            print("Graph generation completed! Output directory:", log_dir)
        
    except ImportError as e:
        print(f"Error: Required module not found: {e}")
        print("Please install required packages: pip3 install --user numpy matplotlib seaborn pandas")
        sys.exit(1)
    except Exception as e:
        print(f"Error during graph generation: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 