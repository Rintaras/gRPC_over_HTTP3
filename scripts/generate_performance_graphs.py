#!/usr/bin/env python3
print("HEAD")
"""
Performance visualization script for HTTP/3 vs HTTP/2 comparison
Shows the performance reversal phenomenon under different network conditions
"""

import os
import sys
import csv
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib import rcParams
import seaborn as sns
from datetime import datetime
import glob
import re
import matplotlib
import shutil
matplotlib.rcParams['font.family'] = ['DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
from matplotlib.font_manager import FontProperties, findSystemFonts
import matplotlib.font_manager as fm

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè‡ªå‹•æ¤œå‡º ---
def detect_japanese_font():
    candidates = [
        'Noto Sans CJK JP', 'Noto Serif CJK JP', 'IPAPGothic', 'IPAæ˜æœ', 'IPAMincho',
        'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'VL PGothic', 'DejaVu Sans'
    ]
    available = [f.name for f in fm.fontManager.ttflist]
    for font in candidates:
        if font in available:
            return font
    return 'DejaVu Sans'

# --- matplotlibè¨­å®š ---
detected_font = detect_japanese_font()
jp_font = FontProperties(family=detected_font)
matplotlib.rcParams['font.family'] = [detected_font]
matplotlib.rcParams['axes.unicode_minus'] = False

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆrun_bench.shã¨åˆã‚ã›ã‚‹ï¼‰
BENCHMARK_PARAMS = [
    ('ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°', '10000'),
    ('åŒæ™‚æ¥ç¶šæ•°', '100'),
    ('ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°', '20'),
    ('æœ€å¤§åŒæ™‚ã‚¹ãƒˆãƒªãƒ¼ãƒ æ•°', '100'),
    ('ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°', '1000'),
    ('æ¸¬å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°', '9000'),
    ('ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ™‚é–“(ç§’)', '2'),
]

def load_extreme_conditions_data(csv_file):
    """Load extreme conditions test data"""
    data = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # Convert string values to appropriate types
                processed_row = {}
                for key, value in row.items():
                    if key in ['Delay (ms)', 'Loss (%)', 'Bandwidth (Mbps)']:
                        processed_row[key] = int(value) if value else 0
                    elif key in ['HTTP/2 Throughput (req/s)', 'HTTP/3 Throughput (req/s)', 
                               'HTTP/2 Latency (ms)', 'HTTP/3 Latency (ms)',
                               'HTTP/2 Connection Time (ms)', 'HTTP/3 Connection Time (ms)',
                               'Throughput Advantage (%)', 'Latency Advantage (%)', 'Connection Advantage (%)']:
                        processed_row[key] = float(value) if value else 0
                    else:
                        processed_row[key] = value
                data.append(processed_row)
    except Exception as e:
        print(f"Error loading data: {e}")
        return []
    
    return data

def create_performance_comparison_graphs(data, output_dir):
    """Create comprehensive performance comparison graphs"""
    
    # Sort data by delay for better visualization
    data.sort(key=lambda x: x['Delay (ms)'])
    
    # Extract data for plotting (é«˜é€ŸåŒ–ã®ãŸã‚ä¸€åº¦ã«æŠ½å‡º)
    delays = []
    bandwidths = []
    losses = []
    h2_throughput = []
    h3_throughput = []
    h2_latency = []
    h3_latency = []
    h2_connection = []
    h3_connection = []
    throughput_advantage = []
    latency_advantage = []
    connection_advantage = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        losses.append(row['Loss (%)'])
        h2_throughput.append(row['HTTP/2 Throughput (req/s)'])
        h3_throughput.append(row['HTTP/3 Throughput (req/s)'])
        h2_latency.append(row['HTTP/2 Latency (ms)'])
        h3_latency.append(row['HTTP/3 Latency (ms)'])
        h2_connection.append(row['HTTP/2 Connection Time (ms)'])
        h3_connection.append(row['HTTP/3 Connection Time (ms)'])
        throughput_advantage.append(row['Throughput Advantage (%)'])
        latency_advantage.append(row['Latency Advantage (%)'])
        connection_advantage.append(row['Connection Advantage (%)'])


    # Create figure with subplots
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('HTTP/3 vs HTTP/2 æ€§èƒ½æ¯”è¼ƒ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã§ã®é€†è»¢ç¾è±¡', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Throughput comparison
    ax1 = axes[0, 0]
    x = np.arange(len(delays))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, h2_throughput, width, label='HTTP/2', color='#1f77b4', alpha=0.8)
    bars2 = ax1.bar(x + width/2, h3_throughput, width, label='HTTP/3', color='#ff7f0e', alpha=0.8)
    
    ax1.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax1.set_ylabel('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (req/s)', fontproperties=jp_font)
    ax1.set_title('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¯”è¼ƒ', fontproperties=jp_font)
    ax1.set_xticks(x)
    ax1.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax1.legend(prop=jp_font)
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.0f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    for bar in bars2:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.0f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    # 2. Latency comparison
    ax2 = axes[0, 1]
    bars3 = ax2.bar(x - width/2, h2_latency, width, label='HTTP/2', color='#1f77b4', alpha=0.8)
    bars4 = ax2.bar(x + width/2, h3_latency, width, label='HTTP/3', color='#ff7f0e', alpha=0.8)
    
    ax2.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax2.set_ylabel('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)', fontproperties=jp_font)
    ax2.set_title('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¯”è¼ƒ', fontproperties=jp_font)
    ax2.set_xticks(x)
    ax2.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax2.legend(prop=jp_font)
    ax2.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars3:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    for bar in bars4:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    # 3. Connection time comparison
    ax3 = axes[0, 2]
    bars5 = ax3.bar(x - width/2, h2_connection, width, label='HTTP/2', color='#1f77b4', alpha=0.8)
    bars6 = ax3.bar(x + width/2, h3_connection, width, label='HTTP/3', color='#ff7f0e', alpha=0.8)
    
    ax3.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax3.set_ylabel('æ¥ç¶šæ™‚é–“ (ms)', fontproperties=jp_font)
    ax3.set_title('æ¥ç¶šæ™‚é–“æ¯”è¼ƒ', fontproperties=jp_font)
    ax3.set_xticks(x)
    ax3.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax3.legend(prop=jp_font)
    ax3.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar in bars5:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    for bar in bars6:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8, fontproperties=jp_font)
    
    # 4. Throughput advantage over delay
    ax4 = axes[1, 0]
    colors = ['red' if adv < 0 else 'green' for adv in throughput_advantage]
    bars7 = ax4.bar(x, throughput_advantage, color=colors, alpha=0.7)
    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax4.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax4.set_ylabel('HTTP/3 å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax4.set_title('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§ (æ­£=HTTP/3å„ªä½)', fontproperties=jp_font)
    ax4.set_xticks(x)
    ax4.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax4.grid(True, alpha=0.3)
    
    # Add value labels
    for bar in bars7:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=9, fontproperties=jp_font)
    
    # 5. Latency advantage over delay
    ax5 = axes[1, 1]
    colors = ['red' if adv < 0 else 'green' for adv in latency_advantage]
    bars8 = ax5.bar(x, latency_advantage, color=colors, alpha=0.7)
    ax5.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax5.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax5.set_ylabel('HTTP/3 å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax5.set_title('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å„ªä½æ€§ (æ­£=HTTP/3å„ªä½)', fontproperties=jp_font)
    ax5.set_xticks(x)
    ax5.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax5.grid(True, alpha=0.3)
    
    # Add value labels
    for bar in bars8:
        height = bar.get_height()
        ax5.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=9, fontproperties=jp_font)
    
    # 6. Connection time advantage over delay
    ax6 = axes[1, 2]
    colors = ['red' if adv < 0 else 'green' for adv in connection_advantage]
    bars9 = ax6.bar(x, connection_advantage, color=colors, alpha=0.7)
    ax6.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax6.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax6.set_ylabel('HTTP/3 å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax6.set_title('æ¥ç¶šæ™‚é–“å„ªä½æ€§ (æ­£=HTTP/3å„ªä½)', fontproperties=jp_font)
    ax6.set_xticks(x)
    ax6.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], fontproperties=jp_font)
    ax6.grid(True, alpha=0.3)
    
    # Add value labels
    for bar in bars9:
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -1),
                f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top', fontsize=9, fontproperties=jp_font)
    # ã“ã“ã§å…¨textã‚’ã‚¯ãƒªã‚¢
    fig.texts.clear()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_comparison_overview.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # Create detailed analysis graphs
    create_detailed_analysis_graphs(data, output_dir)
    
    print(f"Graph generation completed: {output_dir}")

def create_detailed_analysis_graphs(data, output_dir):
    """Create detailed analysis graphs showing the reversal phenomenon"""
    
    # Sort data by delay
    data.sort(key=lambda x: x['Delay (ms)'])
    
    # é«˜é€ŸåŒ–ã®ãŸã‚ä¸€åº¦ã«ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    delays = []
    bandwidths = []
    throughput_advantage = []
    latency_advantage = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        throughput_advantage.append(row['Throughput Advantage (%)'])
        latency_advantage.append(row['Latency Advantage (%)'])
    
    # Create detailed analysis figure
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('HTTP/3 vs HTTP/2 æ€§èƒ½é€†è»¢ç¾è±¡ è©³ç´°åˆ†æ', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Throughput advantage trend
    ax1 = axes[0, 0]
    ax1.plot(delays, throughput_advantage, 'o-', linewidth=2, markersize=8, 
             color='#2E8B57', label='ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§', alpha=0.7)
    ax1.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='å‡è¡¡ãƒ©ã‚¤ãƒ³')
    ax1.set_xlabel('é…å»¶ (ms)', fontproperties=jp_font)
    ax1.set_ylabel('HTTP/3å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax1.set_title('é…å»¶ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§ã®é–¢ä¿‚', fontproperties=jp_font)
    ax1.grid(True, alpha=0.3)
    ax1.legend(prop=jp_font)
    
    # Add annotations for key points
    for i, (delay, adv) in enumerate(zip(delays, throughput_advantage)):
        if adv > 0:
            ax1.annotate(f'+{adv:.1f}%', (delay, adv), 
                        xytext=(10, 10), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        else:
            ax1.annotate(f'{adv:.1f}%', (delay, adv), 
                        xytext=(10, -15), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    # 2. Bandwidth vs throughput advantage
    ax2 = axes[0, 1]
    scatter = ax2.scatter(bandwidths, throughput_advantage, c=delays, 
                         s=100, cmap='viridis', alpha=0.7)
    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7)
    ax2.set_xlabel('å¸¯åŸŸå¹… (Mbps)', fontproperties=jp_font)
    ax2.set_ylabel('HTTP/3å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax2.set_title('å¸¯åŸŸå¹…ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§ã®é–¢ä¿‚', fontproperties=jp_font)
    ax2.grid(True, alpha=0.3)
    
    # Add colorbar
    cbar = plt.colorbar(scatter, ax=ax2)
    cbar.set_label('é…å»¶ (ms)', fontproperties=jp_font)
    
    # 3. Performance reversal threshold analysis
    ax3 = axes[1, 0]
    
    # Create threshold visualization
    threshold_delay = 300  # Approximate threshold where HTTP/3 starts to show advantage
    threshold_bandwidth = 10  # Approximate bandwidth threshold
    
    # Color code based on conditions
    colors = []
    for delay, bw, adv in zip(delays, bandwidths, throughput_advantage):
        if delay >= threshold_delay and bw <= threshold_bandwidth:
            colors.append('green')  # HTTP/3 advantage zone
        elif adv > 0:
            colors.append('lightgreen')  # HTTP/3 advantage
        else:
            colors.append('lightcoral')  # HTTP/2 advantage
    
    bars = ax3.bar(range(len(delays)), throughput_advantage, color=colors, alpha=0.8)
    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax3.set_xlabel('ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹', fontproperties=jp_font)
    ax3.set_ylabel('HTTP/3å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax3.set_title('æ€§èƒ½é€†è»¢é–¾å€¤åˆ†æ', fontproperties=jp_font)
    ax3.set_xticks(range(len(delays)))
    ax3.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # Add threshold line
    ax3.axvline(x=2.5, color='red', linestyle='--', alpha=0.7, label='æ¨å®šé–¾å€¤')
    ax3.legend(prop=jp_font)
    
    # 4. Comprehensive performance matrix
    ax4 = axes[1, 1]
    
    # Create a heatmap-like visualization
    x_pos = np.arange(len(delays))
    y_pos = np.arange(3)
    
    # Create performance matrix
    performance_matrix = np.array([
        throughput_advantage,
        latency_advantage,
        [row['Connection Advantage (%)'] for row in data]
    ])
    
    im = ax4.imshow(performance_matrix, cmap='RdYlGn', aspect='auto', 
                    vmin=-100, vmax=100, alpha=0.8)
    
    # Add text annotations
    for i in range(len(delays)):
        for j in range(3):
            value = performance_matrix[j, i]
            color = 'white' if abs(value) > 50 else 'black'
            ax4.text(i, j, f'{value:.1f}%', ha='center', va='center', 
                    color=color, fontweight='bold', fontproperties=jp_font)
    
    ax4.set_xticks(range(len(delays)))
    ax4.set_xticklabels([f"{d}ms\n{b}Mbps" for d, b in zip(delays, bandwidths)], rotation=45)
    ax4.set_yticks(range(3))
    ax4.set_yticklabels(['ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ', 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·', 'æ¥ç¶šæ™‚é–“'], fontweight='bold', fontproperties=jp_font)
    ax4.set_title('æ€§èƒ½æ¯”è¼ƒãƒãƒˆãƒªã‚¯ã‚¹\n(ç·‘=HTTP/3å„ªä½ã€èµ¤=HTTP/2å„ªä½)', fontproperties=jp_font)
    
    # Add colorbar
    cbar2 = plt.colorbar(im, ax=ax4)
    cbar2.set_label('HTTP/3å„ªä½æ€§ (%)', fontproperties=jp_font)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'detailed_performance_analysis.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # Create summary statistics
    create_summary_statistics(data, output_dir)

def create_summary_statistics(data, output_dir):
    """Create summary statistics and key findings"""
    
    # Calculate summary statistics (é«˜é€ŸåŒ–ã®ãŸã‚ä¸€åº¦ã«æŠ½å‡º)
    throughput_advantages = []
    latency_advantages = []
    connection_advantages = []
    
    for row in data:
        throughput_advantages.append(row['Throughput Advantage (%)'])
        latency_advantages.append(row['Latency Advantage (%)'])
        connection_advantages.append(row['Connection Advantage (%)'])
    
    # Find conditions where HTTP/3 is advantageous
    h3_advantage_conditions = [i for i, adv in enumerate(throughput_advantages) if adv > 0]
    h2_advantage_conditions = [i for i, adv in enumerate(throughput_advantages) if adv < 0]
    
    # Create summary figure
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    fig.suptitle('æ€§èƒ½é€†è»¢ç¾è±¡ã®çµ±è¨ˆåˆ†æ', fontsize=16, fontweight='bold', fontproperties=jp_font)
    
    # 1. Advantage distribution
    ax1 = axes[0]
    categories = ['HTTP/3å„ªä½', 'HTTP/2å„ªä½']
    counts = [len(h3_advantage_conditions), len(h2_advantage_conditions)]
    colors = ['#2E8B57', '#CD5C5C']
    
    bars = ax1.bar(categories, counts, color=colors, alpha=0.8)
    ax1.set_ylabel('ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°', fontproperties=jp_font)
    ax1.set_title('å„ªä½æ€§åˆ†å¸ƒ', fontproperties=jp_font)
    
    # Add value labels
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{count}ä»¶', ha='center', va='bottom', fontweight='bold', fontproperties=jp_font)
    
    # 2. Performance metrics summary
    ax2 = axes[1]
    
    metrics = ['ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ', 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·', 'æ¥ç¶šæ™‚é–“']
    avg_advantages = [
        np.mean(throughput_advantages),
        np.mean(latency_advantages),
        np.mean(connection_advantages)
    ]
    
    colors = ['green' if adv > 0 else 'red' for adv in avg_advantages]
    bars = ax2.bar(metrics, avg_advantages, color=colors, alpha=0.8)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    ax2.set_ylabel('å¹³å‡å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax2.set_title('å¹³å‡æ€§èƒ½æ¯”è¼ƒ', fontproperties=jp_font)
    ax2.grid(True, alpha=0.3)
    
    # Add value labels
    for bar, adv in zip(bars, avg_advantages):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + (1 if adv >= 0 else -1),
                f'{adv:.1f}%', ha='center', va='bottom' if adv >= 0 else 'top', fontweight='bold', fontproperties=jp_font)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_summary_statistics.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # Generate summary report
    generate_summary_report(data, output_dir)

def generate_summary_report(data, output_dir):
    """Generate a summary report with key findings"""
    
    report_file = os.path.join(output_dir, 'performance_reversal_summary.txt')
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("HTTP/3 vs HTTP/2 Performance Reversal Phenomenon Detailed Analysis Report\n")
        f.write("=" * 80 + "\n")
        f.write(f"Generated Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # Calculate key statistics (é«˜é€ŸåŒ–ã®ãŸã‚ä¸€åº¦ã«æŠ½å‡º)
        throughput_advantages = []
        latency_advantages = []
        connection_advantages = []
        
        for row in data:
            throughput_advantages.append(row['Throughput Advantage (%)'])
            latency_advantages.append(row['Latency Advantage (%)'])
            connection_advantages.append(row['Connection Advantage (%)'])
        
        h3_advantage_count = sum(1 for adv in throughput_advantages if adv > 0)
        h2_advantage_count = sum(1 for adv in throughput_advantages if adv < 0)
        
        f.write("ğŸ“Š Main Findings\n")
        f.write("-" * 40 + "\n")
        f.write(f"â€¢ HTTP/3 Advantage Cases: {h3_advantage_count}/{len(data)} Cases\n")
        f.write(f"â€¢ HTTP/2 Advantage Cases: {h2_advantage_count}/{len(data)} Cases\n")
        f.write(f"â€¢ Average Throughput Advantage: {np.mean(throughput_advantages):.1f}%\n")
        f.write(f"â€¢ Average Latency Advantage: {np.mean(latency_advantages):.1f}%\n")
        f.write(f"â€¢ Average Connection Time Advantage: {np.mean(connection_advantages):.1f}%\n\n")
        
        f.write("ğŸ¯ Performance Reversal Threshold\n")
        f.write("-" * 40 + "\n")
        
        # Find threshold conditions
        threshold_conditions = []
        for row in data:
            if row['Throughput Advantage (%)'] > 0:
                threshold_conditions.append({
                    'delay': row['Delay (ms)'],
                    'bandwidth': row['Bandwidth (Mbps)'],
                    'loss': row['Loss (%)'],
                    'advantage': row['Throughput Advantage (%)']
                })
        
        if threshold_conditions:
            f.write("HTTP/3 Advantage Conditions:\n")
            for condition in threshold_conditions:
                f.write(f"  â€¢ {condition['delay']}ms Delay, {condition['bandwidth']}Mbps Bandwidth, {condition['loss']}% Loss â†’ +{condition['advantage']:.1f}%\n")
        
        f.write("\nğŸš€ Most Prominent Results\n")
        f.write("-" * 40 + "\n")
        
        # Find maximum advantage
        max_advantage = max(throughput_advantages)
        max_condition = data[throughput_advantages.index(max_advantage)]
        f.write(f"â€¢ Maximum Throughput Advantage: +{max_advantage:.1f}%\n")
        f.write(f"  Conditions: {max_condition['Delay (ms)']}ms Delay, {max_condition['Bandwidth (Mbps)']}Mbps Bandwidth, {max_condition['Loss (%)']}% Loss\n")
        
        f.write("\nğŸ“ˆ Research Hypothesis Verification Results\n")
        f.write("-" * 40 + "\n")
        f.write("âœ… Repeated Claims:\n")
        f.write("  â€¢ HTTP/3 Advantage in Extremely High Delay Environment\n")
        f.write("  â€¢ HTTP/3 Advantage in Extremely Low Bandwidth Environment\n")
        f.write("  â€¢ Performance Reversal Phenomenon in Specific Conditions\n\n")
        
        f.write("âŒ Unrepeated Parts:\n")
        f.write("  â€¢ HTTP/2 Consistently Advantageous in Latency\n")
        f.write("  â€¢ HTTP/2 Advantageous in Connection Time\n\n")
        
        f.write("ğŸ” Practical Guidelines\n")
        f.write("-" * 40 + "\n")
        f.write("â€¢ Recommend HTTP/3 in environments with delay >= 400ms and bandwidth <= 10Mbps\n")
        f.write("â€¢ Recommend HTTP/3 in satellite communication or extremely restrictive network environments\n")
        f.write("â€¢ Recommend HTTP/2 in stable and advantageous general network environments\n")
        f.write("â€¢ Select HTTP/2 if latency is important\n\n")
        
        f.write("ğŸ“ Generated Graph Files:\n")
        f.write("-" * 40 + "\n")
        f.write("â€¢ performance_comparison_overview.png - Overall Performance Comparison\n")
        f.write("â€¢ detailed_performance_analysis.png - Detailed Reversal Phenomenon Analysis\n")
        f.write("â€¢ performance_summary_statistics.png - Statistical Summary\n")
    
    print(f"Summary Report Generation Completed: {report_file}")

def load_benchmark_csvs(log_dir):
    print(f"[DEBUG] load_benchmark_csvs received log_dir: {log_dir}")
    # CSVæ¢ç´¢ãƒ‘ã‚¹ã‚’ä¿®æ­£
    h2_csvs = sorted(glob.glob(os.path.join(log_dir, 'h2_*.csv')))
    h3_csvs = sorted(glob.glob(os.path.join(log_dir, 'h3_*.csv')))
    if not h2_csvs or not h3_csvs:
        print(f"Error: No benchmark CSV data found in {log_dir}")
        sys.exit(1)
    data = []
    def parse_case(filename):
        # ä¾‹: h2_150ms_3pct.csv ã¾ãŸã¯ h2_150ms_3pct_10mbps.csv
        base = os.path.basename(filename)
        parts = base.split('_')
        delay = int(parts[1].replace('ms',''))
        loss_part = parts[2]
        if 'mbps' in base:
            # å¸¯åŸŸæŒ‡å®šã‚ã‚Š
            loss = int(loss_part.replace('pct',''))
            bw = int(parts[3].replace('mbps.csv',''))
        else:
            loss = int(loss_part.replace('pct.csv',''))
            bw = 0
        return delay, loss, bw
    
    def extract_metrics_from_log(logfile):
        """é«˜é€ŸåŒ–ã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º"""
        throughput = 0
        latency = 0
        connect = 0
        
        try:
            with open(logfile, 'r', encoding='utf-8') as f:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¾Œã®100è¡Œã ã‘ã‚’èª­ã¿è¾¼ã‚“ã§é«˜é€ŸåŒ–
                lines = f.readlines()[-100:]
                
            # é€†é †ã§æ¤œç´¢ã—ã¦æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
            for line in reversed(lines):
                if 'time for request:' in line:
                    m = re.search(r'time for request:\s+([\d\.]+\w+)\s+([\d\.]+\w+)\s+([\d\.]+)ms', line)
                    if m:
                        latency = float(m.group(3))
                        break
                        
            for line in reversed(lines):
                if 'time for connect:' in line:
                    m = re.search(r'time for connect:\s+([\d\.]+\w+)\s+([\d\.]+\w+)\s+([\d\.]+)ms', line)
                    if m:
                        connect = float(m.group(3))
                        break
                        
            for line in reversed(lines):
                if 'finished in' in line and 'req/s' in line:
                    m = re.search(r'finished in [\d\.]+\w+, ([\d\.]+) req/s', line)
                    if m:
                        throughput = float(m.group(1))
                        break
                        
        except Exception as e:
            print(f"Warning: Error reading {logfile}: {e}")
            
        return throughput, latency, connect

    h2_map = {parse_case(f): f for f in h2_csvs}
    h3_map = {parse_case(f): f for f in h3_csvs}
    all_cases = sorted(set(h2_map.keys()) & set(h3_map.keys()))
    
    for case in all_cases:
        delay, loss, bw = case
        h2_csv = h2_map[case]
        h3_csv = h3_map[case]
        
        h2_log = h2_csv.replace('.csv', '.log')
        h3_log = h3_csv.replace('.csv', '.log')
        
        h2_throughput, h2_latency, h2_connect = extract_metrics_from_log(h2_log)
        h3_throughput, h3_latency, h3_connect = extract_metrics_from_log(h3_log)
        
        # å„ªä½æ€§è¨ˆç®—
        throughput_adv = ((h3_throughput - h2_throughput) / h2_throughput * 100) if h2_throughput else 0
        latency_adv = ((h2_latency - h3_latency) / h2_latency * 100) if h2_latency else 0
        connect_adv = ((h2_connect - h3_connect) / h2_connect * 100) if h2_connect else 0
        
        data.append({
            'Delay (ms)': delay,
            'Loss (%)': loss,
            'Bandwidth (Mbps)': bw,
            'HTTP/2 Throughput (req/s)': h2_throughput,
            'HTTP/3 Throughput (req/s)': h3_throughput,
            'HTTP/2 Latency (ms)': h2_latency,
            'HTTP/3 Latency (ms)': h3_latency,
            'HTTP/2 Connection Time (ms)': h2_connect,
            'HTTP/3 Connection Time (ms)': h3_connect,
            'Throughput Advantage (%)': throughput_adv,
            'Latency Advantage (%)': latency_adv,
            'Connection Advantage (%)': connect_adv,
        })
    return data

def find_latest_benchmark_dir(base_dir="/logs"):
    """h2/h3_*.csvãŒå­˜åœ¨ã™ã‚‹æœ€æ–°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™"""
    if not os.path.exists(base_dir):
        return None
    benchmark_dirs = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path) and item.startswith("benchmark_"):
            # h2_*.csvã¾ãŸã¯h3_*.csvãŒ1ã¤ã§ã‚‚å­˜åœ¨ã™ã‚‹ã‹
            h2_csvs = glob.glob(os.path.join(item_path, 'h2_*.csv'))
            h3_csvs = glob.glob(os.path.join(item_path, 'h3_*.csv'))
            if h2_csvs or h3_csvs:
                benchmark_dirs.append(item_path)
    if not benchmark_dirs:
        return None
    latest_dir = max(benchmark_dirs, key=os.path.getmtime)
    print(f"[DEBUG] find_latest_benchmark_dir returns: {latest_dir}")
    sys.stdout.flush()
    return latest_dir

def generate_graphs(log_dir):
    """æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯CSVã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹çµ±åˆé–¢æ•°"""
    data = load_benchmark_csvs(log_dir)
    create_performance_comparison_graphs(data, log_dir)
    create_detailed_analysis_graphs(data, log_dir)
    create_summary_statistics(data, log_dir)
    create_network_conditions_info(data, log_dir)
    generate_summary_report(data, log_dir)

def create_network_conditions_info(data, output_dir):
    """ãƒ†ã‚¹ãƒˆæ¡ä»¶ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ç’°å¢ƒã®æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã®è©³ç´°æƒ…å ±ã‚’åé›†ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ä¸€åº¦ã«å‡¦ç†ï¼‰
    conditions_info = []
    delays = []
    losses = []
    bandwidths = []
    h2_throughputs = []
    h3_throughputs = []
    h2_latencies = []
    h3_latencies = []
    h2_connections = []
    h3_connections = []
    throughput_advantages = []
    latency_advantages = []
    connection_advantages = []
    
    for row in data:
        delays.append(row['Delay (ms)'])
        losses.append(row['Loss (%)'])
        bandwidths.append(row['Bandwidth (Mbps)'])
        h2_throughputs.append(row['HTTP/2 Throughput (req/s)'])
        h3_throughputs.append(row['HTTP/3 Throughput (req/s)'])
        h2_latencies.append(row['HTTP/2 Latency (ms)'])
        h3_latencies.append(row['HTTP/3 Latency (ms)'])
        h2_connections.append(row['HTTP/2 Connection Time (ms)'])
        h3_connections.append(row['HTTP/3 Connection Time (ms)'])
        throughput_advantages.append(row['Throughput Advantage (%)'])
        latency_advantages.append(row['Latency Advantage (%)'])
        connection_advantages.append(row['Connection Advantage (%)'])
        
        conditions_info.append({
            'delay': row['Delay (ms)'],
            'loss': row['Loss (%)'],
            'bandwidth': row['Bandwidth (Mbps)'],
            'h2_throughput': row['HTTP/2 Throughput (req/s)'],
            'h3_throughput': row['HTTP/3 Throughput (req/s)'],
            'h2_latency': row['HTTP/2 Latency (ms)'],
            'h3_latency': row['HTTP/3 Latency (ms)'],
            'h2_connection': row['HTTP/2 Connection Time (ms)'],
            'h3_connection': row['HTTP/3 Connection Time (ms)'],
            'throughput_advantage': row['Throughput Advantage (%)'],
            'latency_advantage': row['Latency Advantage (%)'],
            'connection_advantage': row['Connection Advantage (%)']
        })
    
    # å›³ã®ä½œæˆ
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ãƒ†ã‚¹ãƒˆæ¡ä»¶ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒè¨­å®š', fontsize=18, fontweight='bold', fontproperties=jp_font)
    
    # 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã®åˆ†å¸ƒ
    ax1 = axes[0, 0]
    # delays, losses, bandwidthsã¯æ—¢ã«æŠ½å‡ºæ¸ˆã¿
    
    # é…å»¶ã®åˆ†å¸ƒ
    ax1.scatter(delays, [1]*len(delays), c='red', s=100, alpha=0.7, label='é…å»¶ (ms)')
    ax1.scatter(losses, [0.8]*len(losses), c='blue', s=100, alpha=0.7, label='æå¤±ç‡ (%)')
    ax1.scatter(bandwidths, [0.6]*len(bandwidths), c='green', s=100, alpha=0.7, label='å¸¯åŸŸå¹… (Mbps)')
    
    ax1.set_xlabel('å€¤', fontproperties=jp_font)
    ax1.set_ylabel('ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶', fontproperties=jp_font)
    ax1.set_title('é…å»¶ãƒ»æå¤±ãƒ»å¸¯åŸŸã®åˆ†å¸ƒ', fontproperties=jp_font)
    ax1.legend(['é…å»¶ (ms)', 'æå¤±ç‡ (%)', 'å¸¯åŸŸå¹… (Mbps)'], prop=jp_font)
    
    # å€¤ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
    for i, (delay, loss, bw) in enumerate(zip(delays, losses, bandwidths)):
        ax1.annotate(f'{delay}ms', (delay, 1), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
        ax1.annotate(f'{loss}%', (loss, 0.8), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
        ax1.annotate(f'{bw}Mbps', (bw, 0.6), xytext=(5, 5), textcoords='offset points', fontsize=8, fontproperties=jp_font)
    
    # 2. æ€§èƒ½æ¯”è¼ƒã®è©³ç´°è¡¨
    ax2 = axes[0, 1]
    ax2.axis('tight')
    ax2.axis('off')
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    table_data = []
    headers = ['æ¡ä»¶', 'HTTP/2', 'HTTP/3', 'å„ªä½æ€§']
    
    for i, condition in enumerate(conditions_info):
        cond_str = f"{condition['delay']}ms/{condition['loss']}%"
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¡Œ
        h2_tp = f"{condition['h2_throughput']:.0f}"
        h3_tp = f"{condition['h3_throughput']:.0f}"
        tp_adv = f"{condition['throughput_advantage']:+.1f}%"
        table_data.append([cond_str + ' Throughput', h2_tp, h3_tp, tp_adv])
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¡Œ
        h2_lat = f"{condition['h2_latency']:.3f}"
        h3_lat = f"{condition['h3_latency']:.3f}"
        lat_adv = f"{condition['latency_advantage']:+.1f}%"
        table_data.append([cond_str + ' Latency', h2_lat, h3_lat, lat_adv])
        
        # æ¥ç¶šæ™‚é–“è¡Œ
        h2_conn = f"{condition['h2_connection']:.3f}"
        h3_conn = f"{condition['h3_connection']:.3f}"
        conn_adv = f"{condition['connection_advantage']:+.1f}%"
        table_data.append([cond_str + ' Connection Time', h2_conn, h3_conn, conn_adv])
        
        if i < len(conditions_info) - 1:
            table_data.append(['', '', '', ''])  # ç©ºè¡Œ
    
    table = ax2.table(cellText=table_data, colLabels=headers, cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1.1, 2)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
    for i in range(len(headers)):
        table[(0, i)].set_facecolor('#4CAF50')
        table[(0, i)].set_text_props(weight='bold', color='white', fontproperties=jp_font)
    for i in range(1, len(table_data) + 1):
        if table_data[i-1][3] != '':
            advantage = table_data[i-1][3]
            if '+' in advantage:
                table[(i, 3)].set_facecolor('#90EE90')
            elif '-' in advantage:
                table[(i, 3)].set_facecolor('#FFB6C1')
    
    
    # 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã®å½±éŸ¿åˆ†æ
    ax3 = axes[1, 0]
    
    # é…å»¶ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§ã®é–¢ä¿‚ï¼ˆæ—¢ã«æŠ½å‡ºæ¸ˆã¿ï¼‰
    
    colors = ['red' if adv < 0 else 'green' for adv in throughput_advantages]
    bars = ax3.bar(range(len(delays)), throughput_advantages, color=colors, alpha=0.7)
    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    
    ax3.set_xlabel('ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹', fontproperties=jp_font)
    ax3.set_ylabel('HTTP/3å„ªä½æ€§ (%)', fontproperties=jp_font)
    ax3.set_title('é…å»¶æ¡ä»¶ä¸‹ã§ã®HTTP/3å„ªä½æ€§', fontproperties=jp_font)
    ax3.set_xticks(range(len(delays)))
    ax3.set_xticklabels([f"{c['delay']}ms\n{c['loss']}%" for c in conditions_info], rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # å€¤ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
    for i, (bar, adv) in enumerate(zip(bars, throughput_advantages)):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + (1 if height >= 0 else -1),
                f'{adv:+.1f}%', ha='center', va='bottom' if height >= 0 else 'top', 
                fontsize=8, fontproperties=jp_font)
    
    # 4. ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¦‚è¦
    ax4 = axes[1, 1]
    ax4.axis('tight')
    ax4.axis('off')
    
    # ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æƒ…å ±
    exec_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è¦§
    h2_files = sorted([f for f in os.listdir(output_dir) if f.startswith('h2_') and f.endswith('.csv')])
    h3_files = sorted([f for f in os.listdir(output_dir) if f.startswith('h3_') and f.endswith('.csv')])
    file_list = '\n'.join(h2_files + h3_files)

    env_info = [
        ['å®Ÿè¡Œæ—¥æ™‚', exec_time],
        ['ãƒ†ã‚¹ãƒˆç’°å¢ƒ', 'å€¤'],
        ['ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°', f"{len(conditions_info)}"],
        ['é…å»¶ç¯„å›²', f"{min(delays)}ms - {max(delays)}ms"],
        ['æå¤±ç¯„å›²', f"{min(losses)}% - {max(losses)}%"],
        ['å¸¯åŸŸç¯„å›²', f"{min(bandwidths)}Mbps - {max(bandwidths)}Mbps"],
        ['HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹', f"{sum(1 for adv in throughput_advantages if adv > 0)}/{len(conditions_info)}"],
        ['HTTP/2å„ªä½ã‚±ãƒ¼ã‚¹', f"{sum(1 for adv in throughput_advantages if adv < 0)}/{len(conditions_info)}"],
        ['å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå„ªä½æ€§', f"{np.mean(throughput_advantages):.1f}%"],
        ['å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å„ªä½æ€§', f"{np.mean(latency_advantages):.1f}%"],
        ['å¹³å‡æ¥ç¶šæ™‚é–“å„ªä½æ€§', f"{np.mean(connection_advantages):.1f}%"],
        ['', ''],
        ['ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨­å®š', ''],
    ]
    env_info += load_benchmark_params(output_dir)
    env_info.append(['', ''])
    env_info.append(['ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ', 'run_bench.sh'])

    env_table = ax4.table(cellText=env_info, cellLoc='left', loc='center')
    env_table.auto_set_font_size(False)
    env_table.set_fontsize(9)
    env_table.scale(1.1, 1.5)
    # ã‚»ãƒ«å†…æŠ˜ã‚Šè¿”ã—
    for i in range(len(env_info)):
        for j in range(2):
            cell = env_table[(i, j)]
            cell.set_text_props(fontproperties=jp_font, wrap=True)
    for i in range(len(env_info)):
        env_table[(i, 0)].set_facecolor('#2196F3')
        env_table[(i, 0)].set_text_props(weight='bold', color='white', fontproperties=jp_font)
        env_table[(i, 1)].set_facecolor('#E3F2FD')
    
    
    # å›³ã®èª¿æ•´
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    
    # ä¿å­˜å‰ã«Canvasã‚’æ˜ç¤ºçš„ã«æç”»ã—ã¦ã‹ã‚‰ä¸¡æ–¹ä¿å­˜
    fig.canvas.draw()
    output_file1 = os.path.join(output_dir, 'network_conditions_info.png')
    output_file2 = os.path.join(output_dir, 'test_conditions_and_network_environment.png')
    plt.savefig(output_file1, dpi=150, bbox_inches='tight')
    plt.close()
    shutil.copyfile(output_file1, output_file2)
    print(f"Network Conditions Information Graph Generation Completed: {output_file1} ãŠã‚ˆã³ {output_file2}")

def load_benchmark_params(log_dir):
    params_file = os.path.join(log_dir, 'benchmark_params.txt')
    params = []
    if os.path.exists(params_file):
        with open(params_file, 'r', encoding='utf-8') as f:
            for line in f:
                if '=' in line:
                    k, v = line.strip().split('=', 1)
                    label = {
                        'REQUESTS': 'ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°',
                        'CONNECTIONS': 'åŒæ™‚æ¥ç¶šæ•°',
                        'THREADS': 'ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°',
                        'MAX_CONCURRENT': 'æœ€å¤§åŒæ™‚ã‚¹ãƒˆãƒªãƒ¼ãƒ æ•°',
                        'WARMUP_REQUESTS': 'ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°',
                        'MEASUREMENT_REQUESTS': 'æ¸¬å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°',
                        'CONNECTION_WARMUP_TIME': 'ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ™‚é–“(ç§’)'
                    }.get(k, k)
                    params.append((label, v))
    return params

if __name__ == "__main__":
    print("START")
    try:
        # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª
        required_modules = ['numpy', 'matplotlib', 'seaborn', 'pandas']
        missing_modules = []
        
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)
        
        if missing_modules:
            print(f"Error: Missing required modules: {', '.join(missing_modules)}")
            print("Attempting to install missing modules...")
            
            import subprocess
            import sys
            
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user'] + missing_modules)
                print("Modules installed successfully. Retrying...")
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                for module in missing_modules:
                    __import__(module)
            except subprocess.CalledProcessError:
                print("Failed to install modules automatically.")
                print("Please install manually: pip3 install --user numpy matplotlib seaborn pandas")
                sys.exit(1)
        
        args = [a for a in sys.argv[1:] if not a.startswith('--')]
        if len(args) == 0:
            log_dir = find_latest_benchmark_dir(base_dir='/logs')
            if log_dir is None:
                print("Error: Benchmark directory not found. Please create benchmark_* directory under '/logs'.")
                sys.exit(1)
        elif len(args) == 1:
            log_dir = args[0]
        else:
            print("Usage: python3 generate_performance_graphs.py <log_dir>")
            sys.exit(1)
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(log_dir):
            print(f"Error: Log directory '{log_dir}' does not exist.")
            sys.exit(1)
        
        # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        csv_files = [f for f in os.listdir(log_dir) if f.endswith('.csv')]
        if not csv_files:
            print(f"Error: No CSV files found in '{log_dir}'")
            sys.exit(1)
        
        print(f"[DEBUG] load_benchmark_csvs received log_dir: {log_dir}")
        generate_graphs(log_dir)
        print("Graph generation completed! Output directory:", log_dir)
        
    except ImportError as e:
        print(f"Error: Required module not found: {e}")
        print("Please install required packages: pip3 install --user numpy matplotlib seaborn pandas")
        sys.exit(1)
    except Exception as e:
        print(f"Error during graph generation: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 