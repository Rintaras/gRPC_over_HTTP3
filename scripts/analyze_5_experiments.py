#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
5å›ã®å®Ÿé¨“çµæœã‚’çµ±åˆåˆ†æã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
HTTP/2 vs HTTP/3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã®å†ç¾æ€§ã¨çµ±è¨ˆçš„å®‰å®šæ€§ã‚’è©•ä¾¡
"""

import os
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
import matplotlib.font_manager as fm
import matplotlib as mpl

japanese_fonts = [
    'Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Yu Gothic', 'Meiryo', 
    'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP', 
    'Source Han Sans JP', 'Noto Sans JP', 'M PLUS 1p', 'Kosugi Maru',
    'Hiragino Maru Gothic ProN', 'Yu Gothic UI', 'MS Gothic', 'MS Mincho'
]

available_fonts = [f.name for f in fm.fontManager.ttflist]
font_found = False
selected_font = None

for font in japanese_fonts:
    if font in available_fonts:
        selected_font = font
        font_found = True
        print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šæˆåŠŸ: {font}")
        break

if font_found:
    font_family = [selected_font, 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
    plt.rcParams.update({
        'font.family': font_family,
        'font.sans-serif': font_family,
        'axes.unicode_minus': False,
        'font.size': 10,
        'axes.titlesize': 12,
        'axes.labelsize': 10,
        'xtick.labelsize': 9,
        'ytick.labelsize': 9,
        'legend.fontsize': 9
    })
    mpl.rcParams.update({
        'font.family': font_family,
        'font.sans-serif': font_family,
        'axes.unicode_minus': False
    })
else:
    fallback_fonts = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
    plt.rcParams.update({
        'font.family': fallback_fonts,
        'font.sans-serif': fallback_fonts,
        'axes.unicode_minus': False,
        'font.size': 10,
        'axes.titlesize': 12,
        'axes.labelsize': 10,
        'xtick.labelsize': 9,
        'ytick.labelsize': 9,
        'legend.fontsize': 9
    })
    mpl.rcParams.update({
        'font.family': fallback_fonts,
        'font.sans-serif': fallback_fonts,
        'axes.unicode_minus': False
    })
    print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

class FiveExperimentAnalyzer:
    def __init__(self, logs_dir="logs"):
        self.logs_dir = Path(logs_dir)
        self.experiments = []
        self.consolidated_data = []
        
    def find_japanese_benchmark_experiments(self):
        """æœ€æ–°ã®5å›ã®æ—¥æœ¬èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿé¨“ã‚’æ¤œç´¢"""
        japanese_dirs = []
        for item in self.logs_dir.iterdir():
            if item.is_dir() and item.name.startswith('japanese_benchmark_'):
                japanese_dirs.append(item)
        
        # æœ€æ–°ã®5ã¤ã‚’å–å¾—
        japanese_dirs.sort(key=lambda x: x.name, reverse=True)
        return japanese_dirs[:5]
    
    def parse_summary_file(self, summary_file):
        """ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
        with open(summary_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å®Ÿé¨“æ™‚åˆ»ã‚’æŠ½å‡º
        time_match = re.search(r'Generated Time: (\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', content)
        experiment_time = time_match.group(1) if time_match else "Unknown"
        
        # ä¸»è¦ãªæŒ‡æ¨™ã‚’æŠ½å‡º
        h3_advantage_match = re.search(r'HTTP/3 Advantage Cases: (\d+)/(\d+) Cases', content)
        h2_advantage_match = re.search(r'HTTP/2 Advantage Cases: (\d+)/(\d+) Cases', content)
        
        h3_advantage = int(h3_advantage_match.group(1)) if h3_advantage_match else 0
        total_cases = int(h3_advantage_match.group(2)) if h3_advantage_match else 0
        
        # å¹³å‡æ€§èƒ½å·®ã‚’æŠ½å‡º
        throughput_match = re.search(r'Average Throughput Advantage: ([+-]?\d+\.?\d*)%', content)
        latency_match = re.search(r'Average Latency Advantage: ([+-]?\d+\.?\d*)%', content)
        connection_match = re.search(r'Average Connection Time Advantage: ([+-]?\d+\.?\d*)%', content)
        
        throughput_adv = float(throughput_match.group(1)) if throughput_match else 0.0
        latency_adv = float(latency_match.group(1)) if latency_match else 0.0
        connection_adv = float(connection_match.group(1)) if connection_match else 0.0
        
        # æœ€å¤§æ€§èƒ½å·®ã‚’æŠ½å‡º
        max_throughput_match = re.search(r'Maximum Throughput Advantage: ([+-]?\d+\.?\d*)%', content)
        max_throughput = float(max_throughput_match.group(1)) if max_throughput_match else 0.0
        
        # HTTP/3å„ªä½æ¡ä»¶ã‚’æŠ½å‡º
        h3_conditions = []
        for line in content.split('\n'):
            if 'Delay,' in line and 'Loss â†’' in line:
                condition_match = re.search(r'(\d+)ms Delay, (\d+)Mbps Bandwidth, (\d+\.?\d*)% Loss â†’ ([+-]?\d+\.?\d*)%', line)
                if condition_match:
                    h3_conditions.append({
                        'delay': int(condition_match.group(1)),
                        'bandwidth': int(condition_match.group(2)),
                        'loss': float(condition_match.group(3)),
                        'advantage': float(condition_match.group(4))
                    })
        
        return {
            'experiment_time': experiment_time,
            'h3_advantage_cases': h3_advantage,
            'total_cases': total_cases,
            'h3_advantage_ratio': h3_advantage / total_cases if total_cases > 0 else 0,
            'avg_throughput_advantage': throughput_adv,
            'avg_latency_advantage': latency_adv,
            'avg_connection_advantage': connection_adv,
            'max_throughput_advantage': max_throughput,
            'h3_advantage_conditions': h3_conditions
        }
    
    def load_experiment_data(self):
        """å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        experiment_dirs = self.find_japanese_benchmark_experiments()
        
        print(f"ğŸ“Š æ¤œå‡ºã•ã‚ŒãŸå®Ÿé¨“æ•°: {len(experiment_dirs)}")
        
        for i, exp_dir in enumerate(experiment_dirs, 1):
            print(f"ğŸ” å®Ÿé¨“ {i}: {exp_dir.name}")
            
            summary_file = exp_dir / "performance_reversal_summary.txt"
            if summary_file.exists():
                exp_data = self.parse_summary_file(summary_file)
                exp_data['experiment_id'] = i
                exp_data['experiment_dir'] = exp_dir.name
                self.experiments.append(exp_data)
            else:
                print(f"âš ï¸ ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {summary_file}")
        
        print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(self.experiments)} å®Ÿé¨“")
    
    def analyze_consistency(self):
        """å®Ÿé¨“çµæœã®ä¸€è²«æ€§ã‚’åˆ†æ"""
        if not self.experiments:
            print("âŒ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\n" + "="*80)
        print("ğŸ“ˆ 5å›å®Ÿé¨“çµæœã®ä¸€è²«æ€§åˆ†æ")
        print("="*80)
        
        # åŸºæœ¬çµ±è¨ˆ
        df = pd.DataFrame(self.experiments)
        
        print(f"\nğŸ“Š å®Ÿé¨“æ¦‚è¦:")
        print(f"â€¢ å®Ÿé¨“æœŸé–“: {df['experiment_time'].min()} ã€œ {df['experiment_time'].max()}")
        print(f"â€¢ ç·å®Ÿé¨“æ•°: {len(df)}")
        
        print(f"\nğŸ¯ HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹åˆ†æ:")
        print(f"â€¢ å¹³å‡å„ªä½ã‚±ãƒ¼ã‚¹æ•°: {df['h3_advantage_cases'].mean():.1f}/{df['total_cases'].iloc[0]}")
        print(f"â€¢ å„ªä½ç‡ã®ç¯„å›²: {df['h3_advantage_ratio'].min():.1%} ã€œ {df['h3_advantage_ratio'].max():.1%}")
        print(f"â€¢ æ¨™æº–åå·®: {df['h3_advantage_ratio'].std():.1%}")
        
        print(f"\nâš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·®åˆ†æ:")
        print(f"â€¢ å¹³å‡: {df['avg_throughput_advantage'].mean():.1f}%")
        print(f"â€¢ ç¯„å›²: {df['avg_throughput_advantage'].min():.1f}% ã€œ {df['avg_throughput_advantage'].max():.1f}%")
        print(f"â€¢ æ¨™æº–åå·®: {df['avg_throughput_advantage'].std():.1f}%")
        
        print(f"\nâ±ï¸ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ€§èƒ½å·®åˆ†æ:")
        print(f"â€¢ å¹³å‡: {df['avg_latency_advantage'].mean():.1f}%")
        print(f"â€¢ ç¯„å›²: {df['avg_latency_advantage'].min():.1f}% ã€œ {df['avg_latency_advantage'].max():.1f}%")
        print(f"â€¢ æ¨™æº–åå·®: {df['avg_latency_advantage'].std():.1f}%")
        
        print(f"\nğŸ”— æ¥ç¶šæ™‚é–“æ€§èƒ½å·®åˆ†æ:")
        print(f"â€¢ å¹³å‡: {df['avg_connection_advantage'].mean():.1f}%")
        print(f"â€¢ ç¯„å›²: {df['avg_connection_advantage'].min():.1f}% ã€œ {df['avg_connection_advantage'].max():.1f}%")
        print(f"â€¢ æ¨™æº–åå·®: {df['avg_connection_advantage'].std():.1f}%")
        
        # ä¸€è²«æ€§è©•ä¾¡
        print(f"\nğŸ” ä¸€è²«æ€§è©•ä¾¡:")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å¤‰å‹•ä¿‚æ•°
        throughput_cv = abs(df['avg_throughput_advantage'].std() / df['avg_throughput_advantage'].mean()) if df['avg_throughput_advantage'].mean() != 0 else float('inf')
        print(f"â€¢ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¤‰å‹•ä¿‚æ•°: {throughput_cv:.3f} ({'é«˜å®‰å®š' if throughput_cv < 0.1 else 'ä¸­å®‰å®š' if throughput_cv < 0.3 else 'ä½å®‰å®š'})")
        
        # HTTP/3å„ªä½ã®ä¸€è²«æ€§
        h3_consistent = df['h3_advantage_cases'].std() == 0
        print(f"â€¢ HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹ä¸€è²«æ€§: {'âœ… å®Œå…¨ä¸€è²«' if h3_consistent else 'âš ï¸ å¤‰å‹•ã‚ã‚Š'}")
        
        # æœ€å¤§æ€§èƒ½å·®ã®ä¸€è²«æ€§
        max_throughput_cv = abs(df['max_throughput_advantage'].std() / df['max_throughput_advantage'].mean()) if df['max_throughput_advantage'].mean() != 0 else float('inf')
        print(f"â€¢ æœ€å¤§æ€§èƒ½å·®å¤‰å‹•ä¿‚æ•°: {max_throughput_cv:.3f}")
        
        return df
    
    def analyze_network_conditions_impact(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã®å½±éŸ¿ã‚’åˆ†æ"""
        print(f"\nğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶å½±éŸ¿åˆ†æ:")
        
        # å„å®Ÿé¨“ã®HTTP/3å„ªä½æ¡ä»¶ã‚’é›†è¨ˆ
        all_conditions = []
        for exp in self.experiments:
            for condition in exp['h3_advantage_conditions']:
                condition['experiment_id'] = exp['experiment_id']
                all_conditions.append(condition)
        
        if not all_conditions:
            print("â€¢ HTTP/3å„ªä½æ¡ä»¶: æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        conditions_df = pd.DataFrame(all_conditions)
        
        print(f"â€¢ HTTP/3å„ªä½æ¡ä»¶ç·æ•°: {len(conditions_df)}")
        print(f"â€¢ å¹³å‡æ€§èƒ½å‘ä¸Š: {conditions_df['advantage'].mean():.1f}%")
        print(f"â€¢ æœ€å¤§æ€§èƒ½å‘ä¸Š: {conditions_df['advantage'].max():.1f}%")
        
        # é…å»¶æ¡ä»¶åˆ¥åˆ†æ
        delay_groups = conditions_df.groupby('delay')
        print(f"\nğŸ“Š é…å»¶æ¡ä»¶åˆ¥åˆ†æ:")
        for delay, group in delay_groups:
            print(f"â€¢ {delay}msé…å»¶: {len(group)}å›æ¤œå‡º, å¹³å‡æ€§èƒ½å‘ä¸Š: {group['advantage'].mean():.1f}%")
        
        return conditions_df
    
    def generate_consistency_graphs(self, df):
        """ä¸€è²«æ€§åˆ†æã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('5å›å®Ÿé¨“çµæœã®ä¸€è²«æ€§åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹æ•°ã®æ¨ç§»
        ax1 = axes[0, 0]
        ax1.plot(df['experiment_id'], df['h3_advantage_cases'], 'bo-', linewidth=2, markersize=8)
        ax1.set_xlabel('å®Ÿé¨“å›æ•°')
        ax1.set_ylabel('HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹æ•°')
        ax1.set_title('HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹æ•°ã®æ¨ç§»')
        ax1.grid(True, alpha=0.3)
        ax1.set_xticks(df['experiment_id'])
        
        # 2. å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·®ã®æ¨ç§»
        ax2 = axes[0, 1]
        ax2.plot(df['experiment_id'], df['avg_throughput_advantage'], 'ro-', linewidth=2, markersize=8)
        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax2.set_xlabel('å®Ÿé¨“å›æ•°')
        ax2.set_ylabel('å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·® (%)')
        ax2.set_title('å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·®ã®æ¨ç§»')
        ax2.grid(True, alpha=0.3)
        ax2.set_xticks(df['experiment_id'])
        
        # 3. æ€§èƒ½å·®ã®åˆ†å¸ƒï¼ˆç®±ã²ã’å›³ï¼‰
        ax3 = axes[1, 0]
        performance_metrics = ['avg_throughput_advantage', 'avg_latency_advantage', 'avg_connection_advantage']
        labels = ['ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ', 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼', 'æ¥ç¶šæ™‚é–“']
        
        data_for_box = [df[metric] for metric in performance_metrics]
        bp = ax3.boxplot(data_for_box, labels=labels, patch_artist=True)
        
        # è‰²åˆ†ã‘
        colors = ['lightblue', 'lightcoral', 'lightgreen']
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        ax3.set_ylabel('æ€§èƒ½å·® (%)')
        ax3.set_title('æ€§èƒ½å·®ã®åˆ†å¸ƒ')
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        # 4. æœ€å¤§æ€§èƒ½å·®ã®æ¨ç§»
        ax4 = axes[1, 1]
        ax4.plot(df['experiment_id'], df['max_throughput_advantage'], 'go-', linewidth=2, markersize=8)
        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax4.set_xlabel('å®Ÿé¨“å›æ•°')
        ax4.set_ylabel('æœ€å¤§ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·® (%)')
        ax4.set_title('æœ€å¤§ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å·®ã®æ¨ç§»')
        ax4.grid(True, alpha=0.3)
        ax4.set_xticks(df['experiment_id'])
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_dir = Path("logs") / f"five_experiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        output_dir.mkdir(exist_ok=True)
        
        plt.savefig(output_dir / "consistency_analysis.png", dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ä¸€è²«æ€§åˆ†æã‚°ãƒ©ãƒ•ä¿å­˜: {output_dir / 'consistency_analysis.png'}")
        
        return output_dir
    
    def generate_detailed_report(self, df, conditions_df, output_dir):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_file = output_dir / "five_experiment_analysis_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("5å›å®Ÿé¨“çµæœçµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("="*80 + "\n")
            f.write(f"ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ğŸ“Š å®Ÿé¨“æ¦‚è¦\n")
            f.write("-" * 40 + "\n")
            f.write(f"â€¢ å®Ÿé¨“æœŸé–“: {df['experiment_time'].min()} ã€œ {df['experiment_time'].max()}\n")
            f.write(f"â€¢ ç·å®Ÿé¨“æ•°: {len(df)}\n")
            f.write(f"â€¢ å®Ÿé¨“é–“éš”: ç´„{self._calculate_interval(df)}åˆ†\n\n")
            
            f.write("ğŸ¯ ä¸»è¦ç™ºè¦‹äº‹é …\n")
            f.write("-" * 40 + "\n")
            
            # HTTP/3å„ªä½ã®ä¸€è²«æ€§
            h3_advantage_std = df['h3_advantage_cases'].std()
            if h3_advantage_std == 0:
                f.write("â€¢ HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹: å®Œå…¨ã«ä¸€è²«ã—ãŸçµæœ\n")
            else:
                f.write(f"â€¢ HTTP/3å„ªä½ã‚±ãƒ¼ã‚¹: å¤‰å‹•ã‚ã‚Š (æ¨™æº–åå·®: {h3_advantage_std:.1f})\n")
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½ã®å®‰å®šæ€§
            throughput_cv = abs(df['avg_throughput_advantage'].std() / df['avg_throughput_advantage'].mean()) if df['avg_throughput_advantage'].mean() != 0 else float('inf')
            f.write(f"â€¢ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½å®‰å®šæ€§: å¤‰å‹•ä¿‚æ•° {throughput_cv:.3f}\n")
            
            # æœ€å¤§æ€§èƒ½å·®ã®å‚¾å‘
            max_throughput_trend = "å‘ä¸Š" if df['max_throughput_advantage'].iloc[-1] > df['max_throughput_advantage'].iloc[0] else "ä½ä¸‹"
            f.write(f"â€¢ æœ€å¤§æ€§èƒ½å·®å‚¾å‘: {max_throughput_trend}\n\n")
            
            f.write("ğŸ“ˆ çµ±è¨ˆçš„å®‰å®šæ€§è©•ä¾¡\n")
            f.write("-" * 40 + "\n")
            
            metrics = [
                ('avg_throughput_advantage', 'ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ'),
                ('avg_latency_advantage', 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼'),
                ('avg_connection_advantage', 'æ¥ç¶šæ™‚é–“')
            ]
            
            for metric, name in metrics:
                mean_val = df[metric].mean()
                std_val = df[metric].std()
                cv = abs(std_val / mean_val) if mean_val != 0 else float('inf')
                
                stability = "é«˜å®‰å®š" if cv < 0.1 else "ä¸­å®‰å®š" if cv < 0.3 else "ä½å®‰å®š"
                f.write(f"â€¢ {name}: å¹³å‡{mean_val:.1f}%, æ¨™æº–åå·®{std_val:.1f}%, å¤‰å‹•ä¿‚æ•°{cv:.3f} ({stability})\n")
            
            f.write("\nğŸ” å®Ÿç”¨çš„ãªæ¨å¥¨äº‹é …\n")
            f.write("-" * 40 + "\n")
            
            # ä¸€è²«æ€§ã«åŸºã¥ãæ¨å¥¨
            if h3_advantage_std == 0:
                f.write("â€¢ å®Ÿé¨“çµæœã¯é«˜ã„å†ç¾æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹\n")
                f.write("â€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶ã«å¿œã˜ãŸãƒ—ãƒ­ãƒˆã‚³ãƒ«é¸æŠãŒå¯èƒ½\n")
            else:
                f.write("â€¢ å®Ÿé¨“çµæœã«å¤‰å‹•ãŒã‚ã‚‹ãŸã‚ã€è¤‡æ•°å›æ¸¬å®šã‚’æ¨å¥¨\n")
                f.write("â€¢ çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹æœ‰æ„æ€§ç¢ºèªãŒå¿…è¦\n")
            
            # æ€§èƒ½å·®ã®å®Ÿç”¨æ€§
            avg_throughput = df['avg_throughput_advantage'].mean()
            if abs(avg_throughput) < 5:
                f.write("â€¢ å¹³å‡çš„ãªæ€§èƒ½å·®ã¯5%æœªæº€ã§ã€å®Ÿç”¨ä¸Šã¯åŒç­‰\n")
            else:
                f.write(f"â€¢ å¹³å‡çš„ãªæ€§èƒ½å·®ã¯{abs(avg_throughput):.1f}%ã§ã€å®Ÿç”¨çš„ãªå·®ãŒã‚ã‚‹\n")
            
            f.write("\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«\n")
            f.write("-" * 40 + "\n")
            f.write("â€¢ consistency_analysis.png - ä¸€è²«æ€§åˆ†æã‚°ãƒ©ãƒ•\n")
            f.write("â€¢ five_experiment_analysis_report.txt - ã“ã®ãƒ¬ãƒãƒ¼ãƒˆ\n")
        
        print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
    
    def _calculate_interval(self, df):
        """å®Ÿé¨“é–“éš”ã‚’è¨ˆç®—"""
        if len(df) < 2:
            return 0
        
        times = pd.to_datetime(df['experiment_time'])
        intervals = []
        for i in range(1, len(times)):
            interval = (times.iloc[i] - times.iloc[i-1]).total_seconds() / 60
            intervals.append(interval)
        
        return sum(intervals) / len(intervals)
    
    def run_analysis(self):
        """å®Œå…¨ãªåˆ†æã‚’å®Ÿè¡Œ"""
        print("ğŸš€ 5å›å®Ÿé¨“çµæœçµ±åˆåˆ†æã‚’é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.load_experiment_data()
        
        if not self.experiments:
            print("âŒ åˆ†æå¯èƒ½ãªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # ä¸€è²«æ€§åˆ†æ
        df = self.analyze_consistency()
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¡ä»¶å½±éŸ¿åˆ†æ
        conditions_df = self.analyze_network_conditions_impact()
        
        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        output_dir = self.generate_consistency_graphs(df)
        
        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_detailed_report(df, conditions_df, output_dir)
        
        print(f"\nâœ… åˆ†æå®Œäº†ï¼çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    analyzer = FiveExperimentAnalyzer()
    analyzer.run_analysis() 